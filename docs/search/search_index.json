{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#robotdart","title":"RobotDART","text":"<p>RobotDART is a C++11 robot simulator (with optional Python bindings) built on top of the DART physics engine. The RobotDART simulator is intended to be used by Robotics and Machine Learning researchers who want to write controllers or test learning algorithms without the delays and overhead that usually comes with other simulators (e.g., Gazebo, Coppelia-sim).</p> <p>For this reason, the simulator runs headless by default, and there is the possibility of rendering the scene (e.g., through a camera sensor) without opening a graphics window. All RobotDART's code is thread-safe (including graphics and camera sensors), and thus enables its users to use their code in parallel jobs in multicore computers.</p> <p></p> <p>In a few words, RobotDART combines:</p> <ul> <li>a physics engine (DART)</li> <li>an optional graphics engine (Magnum)</li> <li>a few sensor classes (IMU, force/torque sensors, cameras, etc.)</li> <li>a curated URDF library</li> <li>... and a few useful features to make the life of roboticists/researchers easier</li> </ul> <p> </p>"},{"location":"#main-features","title":"Main Features","text":"<ul> <li>Modern C++ code that makes it easy to develop environments and applications</li> <li>Fast and reliable simulation of robotic mechanisms and their interactions (through the DART physics engine)</li> <li>A structured <code>Robot</code> class that enables a unified creation and access to all important values: in RobotDART you can load any robot description file (URDF, SDF, SKEL, and MuJoCo files) with the same command, and all robot measurements can be queried without using any DART code</li> <li>A generic <code>RobotControl</code> class that enables fast prototyping of any type of controller</li> <li>A generic <code>Sensor</code> class that allows the creation of any kind of sensor</li> <li>A growing list of already implemented sensors, that includes 6-axis <code>ForceTorque</code>, <code>IMU</code>, <code>RGB</code>, and <code>RGB-D</code> sensors</li> <li>A simulation class (<code>RobotDARTSimu</code>) that handles multiple robots and sensors, and allows for step-by-step simulation</li> <li>A growing list of supported robots along with edited and optimized models to be used with RobotDART (see the robots page for details and examples):<ul> <li>PAL Talos humanoid</li> <li>Franka Emika Panda</li> <li>KUKA LBR Iiwa (14kg version)</li> <li>IIT iCub humanoid (without hands)</li> <li>Unitree A1 quadruped robot</li> <li>Dynamixel-based 6-legged robot</li> <li>A simple arm for educational purposes</li> <li>and you can use any URDF</li> </ul> </li> <li>A custom graphical interface built on top of Magnum that allows generic customization</li> <li>Support for windowless OpenGL context creation (even in parallel threads!) to allow for camera sensor usage even in parallel jobs running on clusters</li> <li>Support for video recording in simulation time (i.e., not affected by delays of simulator and/or graphics) for visualization or debugging purposes</li> <li>Full-featured Python bindings for fast prototyping</li> <li>RobotDART runs on any Linux distribution and Mac OS</li> </ul>"},{"location":"#what-robotdart-is-not","title":"What RobotDART is not","text":"<ul> <li>RobotDART is primarily intended to be non-interactive (run a simulation, record/view the result),</li> <li>Interaction is limited to changing the view and your own code. No GUI for adding objects or interactively build an environment,</li> <li>RobotDART is not optimized for wheeled robots,</li> <li>RobotDART is not optimized for simulating complex (e.g., mountain-like) terrains.</li> </ul>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#frequently-asked-questions","title":"Frequently Asked Questions","text":"<p>This pages provides a user guide of the library through Frequently Asked Questions (FAQ).</p>"},{"location":"faq/#what-is-a-minimal-working-example-of-robotdart","title":"What is a minimal working example of RobotDART?","text":"<p>You can find a minimal working example at hello_world.cpp. This example is creating a world where a hexapod robot is placed just above a floor and left to fall. The robot has no actuation, and there is the simplest graphics configuration. Let's split it down.</p> <ul> <li>We first include the appropriate files:</li> </ul> C++Python <pre><code>#include &lt;robot_dart/robot_dart_simu.hpp&gt;\n#ifdef GRAPHIC\n#include &lt;robot_dart/gui/magnum/graphics.hpp&gt;\n#endif\n</code></pre> <pre><code>import RobotDART as rd\n</code></pre> <ul> <li>We then load our hexapod robot:</li> </ul> C++Python <pre><code>auto robot = std::make_shared&lt;robot_dart::Robot&gt;(\"pexod.urdf\");\n</code></pre> <pre><code>robot = rd.Robot(\"pexod.urdf\");\n</code></pre> <ul> <li>We need to place it above the floor to avoid collision (we can use RobotDART's helpers ;)):</li> </ul> C++Python <pre><code>robot-&gt;set_base_pose(robot_dart::make_tf({0., 0., 0.2}));\n</code></pre> <pre><code>robot.set_base_pose([0., 0., 0., 0., 0., 0.2])\n</code></pre> <ul> <li>We can now create the simulation object and add the robot and the floor:</li> </ul> C++Python <pre><code>robot_dart::RobotDARTSimu simu(0.001); // dt=0.001, 1KHz simulation\nsimu.add_floor();\nsimu.add_robot(robot);\n</code></pre> <pre><code>simu = rd.RobotDARTSimu(0.001); # dt=0.001, 1KHz simulation\nsimu.add_floor();\nsimu.add_robot(robot);\n</code></pre> <ul> <li>If needed or wanted, we can add a graphics component to visualize the scene:</li> </ul> C++Python <pre><code>auto graphics = std::make_shared&lt;robot_dart::gui::magnum::Graphics&gt;();\nsimu.set_graphics(graphics);\ngraphics-&gt;look_at({0.5, 3., 0.75}, {0.5, 0., 0.2});\n</code></pre> <pre><code>graphics = rd.gui.Graphics()\nsimu.set_graphics(graphics)\ngraphics.look_at([0.5, 3., 0.75], [0.5, 0., 0.2])\n</code></pre> <ul> <li>Once everything is configured, we can run our simulation for a few seconds:</li> </ul> C++Python <pre><code>simu.run(10.);\n</code></pre> <pre><code>simu.run(10.)\n</code></pre> <ul> <li>Here's how it looks:</li> </ul> <p> </p>"},{"location":"faq/#what-robots-are-supported-in-robotdart","title":"What robots are supported in RobotDART?","text":"<p>RobotDART supports any robot that can be described by a URDF, SDF, SKEL or MJCF file. Nevertheless, we have a curated list of robots with edited and optimized models to be used with RobotDART (see the robots page for details and examples).</p>"},{"location":"faq/#how-can-i-load-my-own-urdfsdfskelmjcf-file","title":"How can I load my own URDF/SDF/SKEL/MJCF file?","text":"<p>See the robots page for details.</p>"},{"location":"faq/#how-do-i-enable-graphics-in-my-code","title":"How do I enable graphics in my code?","text":"<p>To enable graphics in your code, you need to do the following:</p> <ul> <li>Install Magnum. See the installation page for details.</li> <li>Create and set a graphics object in the simulation object. Here's an example:</li> </ul> C++Python <pre><code>auto graphics = std::make_shared&lt;robot_dart::gui::magnum::Graphics&gt;();\nsimu.set_graphics(graphics);\ngraphics-&gt;look_at({0.5, 3., 0.75}, {0.5, 0., 0.2});\n</code></pre> <pre><code>graphics = rd.gui.Graphics()\nsimu.set_graphics(graphics)\ngraphics.look_at([0.5, 3., 0.75], [0.5, 0., 0.2])\n</code></pre>"},{"location":"faq/#i-want-to-have-multiple-camera-sensors-is-it-possible","title":"I want to have multiple camera sensors. Is it possible?","text":"<p>Having multiple camera sensors is indeed possible. We can add as many cameras as we wish along the main camera defined in How do I record a video:</p> C++Python <pre><code>// Add camera\nauto camera = std::make_shared&lt;robot_dart::sensor::Camera&gt;(graphics-&gt;magnum_app(), 256, 256);\n</code></pre> <pre><code># Add camera\ncamera = rd.sensor.Camera(graphics.magnum_app(), 32, 32)\n</code></pre>"},{"location":"faq/#how-do-i-record-a-video","title":"How do I record a video?","text":"<p>In order to record a video of what the main or any other camera \"sees\", you need to call the function <code>record_video(path)</code> of the graphics class:</p> C++Python <pre><code>graphics-&gt;record_video(\"talos_dancing.mp4\");\n</code></pre> <pre><code>graphics.record_video(\"talos_dancing.mp4\")\n</code></pre> <p>Or the camera class:</p> C++Python <pre><code>// cameras can also record video\ncamera-&gt;record_video(\"video-camera.mp4\");\n</code></pre> <pre><code># cameras can also record video\ncamera.record_video(\"video-camera.mp4\")\n</code></pre>"},{"location":"faq/#how-can-i-position-a-camera-to-the-environment","title":"How can I position a camera to the environment?","text":"<p>In order to position a camera inside the world, we need to use the <code>lookAt</code> method of the camera/graphics object:</p> C++Python <pre><code>// set the position of the camera, and the position where the main camera is looking at\nEigen::Vector3d cam_pos = {-0.5, -3., 0.75};\nEigen::Vector3d cam_looks_at = {0.5, 0., 0.2};\ncamera-&gt;look_at(cam_pos, cam_looks_at);\n</code></pre> <pre><code># set the position of the camera, and the position where the main camera is looking at\ncam_pos = [-0.5, -3., 0.75]\ncam_looks_at = [0.5, 0., 0.2]\ncamera.look_at(cam_pos, cam_looks_at)\n</code></pre>"},{"location":"faq/#how-can-i-attach-a-camera-to-a-moving-link","title":"How can I attach a camera to a moving link?","text":"<p>Cameras can be easily attached to a moving link:</p> C++Python <pre><code>Eigen::Isometry3d tf;\ntf = Eigen::AngleAxisd(3.14, Eigen::Vector3d{1., 0., 0.});\ntf *= Eigen::AngleAxisd(1.57, Eigen::Vector3d{0., 0., 1.});\ntf.translation() = Eigen::Vector3d(0., 0., 0.1);\ncamera-&gt;attach_to_body(robot-&gt;body_node(\"iiwa_link_ee\"), tf); // cameras are looking towards -z by default\n</code></pre> <pre><code>tf = dartpy.math.Isometry3()\nrot =  dartpy.math.AngleAxis(3.14, [1., 0., 0.])\nrot = rot.multiply( dartpy.math.AngleAxis(1.57, [0., 0., 1.])).to_rotation_matrix()\ntf.set_translation([0., 0., 0.1])\ncamera.attach_to_body(robot.body_node(\"iiwa_link_ee\"), tf) # cameras are looking towards -z by default\n</code></pre>"},{"location":"faq/#how-can-i-manipulate-the-camera-object","title":"How can I manipulate the camera object?","text":"<p>Every camera has its own parameters, i.e a Near plane, a far plane, a Field Of View (FOV), a width and a height (that define the aspect ratio), you can manipulate each one separately:</p> C++Python <pre><code>camera-&gt;camera().set_far_plane(5.f);\ncamera-&gt;camera().set_near_plane(0.01f);\ncamera-&gt;camera().set_fov(60.0f);\n</code></pre> <pre><code>camera.camera().set_far_plane(5.)\ncamera.camera().set_near_plane(0.01)\ncamera.camera().set_fov(60.0)\n</code></pre> <p>or all at once:</p> C++Python <pre><code>camera-&gt;camera().set_camera_params(5., // far plane\n0.01f, // near plane\n60.0f, // field of view\n600, // width\n400 // height\n);\n</code></pre> <pre><code>camera.camera().set_camera_params(5., #far plane\n0.01, #near plane\n60.0, # field of view\n600, # width\n400) #height\n</code></pre> <p>You can find a complete example at cameras.cpp.</p>"},{"location":"faq/#how-can-i-interact-with-the-camera","title":"How can I interact with the camera?","text":"<p>We can move translate the cameras with the <code>WASD</code> keys, zoom in and out using the <code>mouse wheel</code> and rotate the camera with holding the <code>left mouse key</code> and moving the mouse.</p>"},{"location":"faq/#what-do-the-numbers-in-the-status-bar-mean","title":"What do the numbers in the status bar mean?","text":"<p>The status bar looks like this:</p> <p></p> <p>Where simulation time gives us the total simulated time (in seconds), wall time gives us the total time (in seconds) that has passed in real-time once we have started simulating. The next number X.Xx gives us the real-time factor: for example, 1.1x means that the simulation runs 1.1 times faster than real-time, whereas 0.7x means that the simulation runs slower than real-time. The value it: XX ms reports the time it took the last iteration (in milliseconds). The last part gives us whether the simulation tries to adhere to real-time or not. sync means that RobotDART will slow down the simulation in order for it to be in real-time, whereas no-sync means that RobotDART will try to run the simulation as fast as possible.</p>"},{"location":"faq/#how-can-i-alter-the-graphics-scene-eg-change-lighting-conditions","title":"How can I alter the graphics scene (e.g., change lighting conditions)?","text":"<p>When creating a graphics object, you can pass a <code>GraphicsConfiguration</code> object that changes the default values:</p> C++Python <pre><code>robot_dart::gui::magnum::GraphicsConfiguration configuration;\n// We can change the width/height of the window (or camera image dimensions)\nconfiguration.width = 1280;\nconfiguration.height = 960;\nconfiguration.title = \"Graphics Tutorial\"; // We can set a title for our window\n// We can change the configuration for shadows\nconfiguration.shadowed = true;\nconfiguration.transparent_shadows = true;\nconfiguration.shadow_map_size = 1024;\n// We can also alter some specifications for the lighting\nconfiguration.max_lights = 3; // maximum number of lights for our scene [default=3]\nconfiguration.specular_strength = 0.25; // strength of the specular component\n// Some extra configuration for the main camera\nconfiguration.draw_main_camera = true;\nconfiguration.draw_debug = true;\nconfiguration.draw_text = true;\n// We can also change the background color [default=black]\nconfiguration.bg_color = Eigen::Vector4d{1.0, 1.0, 1.0, 1.0};\n// Create the graphics object with the configuration as parameter\nauto graphics = std::make_shared&lt;robot_dart::gui::magnum::Graphics&gt;(configuration);\n</code></pre> <pre><code>configuration = rd.gui.GraphicsConfiguration()\n# We can change the width/height of the window (or camera, dimensions)\nconfiguration.width = 1280\nconfiguration.height = 960\nconfiguration.title = \"Graphics Tutorial\"  # We can set a title for our window\n# We can change the configuration for shadows\nconfiguration.shadowed = True\nconfiguration.transparent_shadows = True\nconfiguration.shadow_map_size = 1024\n# We can also alter some specifications for the lighting\nconfiguration.max_lights = 3  # maximum number of lights for our scene\nconfiguration.specular_strength = 0.25  # strength og the specular component\n#  Some extra configuration for the main camera\nconfiguration.draw_main_camera = True\nconfiguration.draw_debug = True\nconfiguration.draw_text = True\n# We can also change the background color [default = black]\nconfiguration.bg_color = [1., 1., 1., 1.]\n# create the graphics object with the configuration as a parameter\ngraphics = rd.gui.Graphics(configuration)\n</code></pre> <p>You can disable or enable shadows on the fly as well:</p> C++Python <pre><code>// Disable shadows\ngraphics-&gt;enable_shadows(false, false);\nsimu.run(1.);\n// Enable shadows only for non-transparent objects\ngraphics-&gt;enable_shadows(true, false);\nsimu.run(1.);\n// Enable shadows for transparent objects as well\ngraphics-&gt;enable_shadows(true, true);\nsimu.run(1.);\n</code></pre> <pre><code># Disable shadows\ngraphics.enable_shadows(False, False)\nsimu.run(1.)\n# Enable shadows only for non-transparent objects\ngraphics.enable_shadows(True, False)\nsimu.run(1.)\n# Enable shadows for transparent objects as well\ngraphics.enable_shadows(True, True)\nsimu.run(1.)\n</code></pre> <p>You can also add your own lights. The application by default creates 2 light sources and the maximum number of lights is 3 (you can change this once before the creation of the graphics object via the <code>GraphicsConfiguration</code> object). So usually before you add your lights, you have to clear the default lights:</p> C++Python <pre><code>// Clear Lights\ngraphics-&gt;clear_lights();\n</code></pre> <pre><code># Clear Lights\ngraphics.clear_lights()\n</code></pre> <p>Then you must create a custom light material:</p> C++Python <pre><code>// Create Light material\nMagnum::Float shininess = 1000.f;\nMagnum::Color4 white = {1.f, 1.f, 1.f, 1.f};\n// ambient, diffuse, specular\nauto custom_material = robot_dart::gui::magnum::gs::Material(white, white, white, shininess);\n</code></pre> <pre><code># Clear Light material\nshininess = 1000.\nwhite = magnum.Color4(1., 1., 1., 1.)\n# ambient, diffuse, specular\ncustom_material = rd.gui.Material(white, white, white, shininess)\n</code></pre> <p>Now you can add on ore more of the following lights:</p> <p>Point Light:</p> C++Python <pre><code>// Create point light\nMagnum::Vector3 position = {0.f, 0.f, 2.f};\nMagnum::Float intensity = 1.f;\nMagnum::Vector3 attenuation_terms = {1.f, 0.f, 0.f};\nauto point_light = robot_dart::gui::magnum::gs::create_point_light(position, custom_material, intensity, attenuation_terms);\ngraphics-&gt;add_light(point_light);\n</code></pre> <pre><code># Create point light\nposition = magnum.Vector3(0., 0., 2.)\nintensity = 1.\nattenuation_terms = magnum.Vector3(1., 0., 0.)\npoint_light = rd.gui.create_point_light(position, custom_material, intensity, attenuation_terms)\ngraphics.add_light(point_light)\n</code></pre> <p>Spot Light:</p> C++Python <pre><code>// Create spot light\nMagnum::Vector3 position = {0.f, 0.f, 1.f};\nMagnum::Vector3 direction = {-1.f, -1.f, -1.f};\nMagnum::Float intensity = 1.f;\nMagnum::Vector3 attenuation_terms = {1.f, 0.f, 0.f};\nMagnum::Float spot_exponent = M_PI;\nMagnum::Float spot_cut_off = M_PI / 8;\nauto spot_light = robot_dart::gui::magnum::gs::create_spot_light(position, custom_material, direction, spot_exponent, spot_cut_off, intensity, attenuation_terms);\ngraphics-&gt;add_light(spot_light);\n</code></pre> <pre><code># Create spot light\nposition = magnum.Vector3(0., 0., 1.)\ndirection = magnum.Vector3(-1, -1, -1)\nintensity = 1.\nattenuation_terms = magnum.Vector3(1., 0., 0.)\nspot_exponent = np.pi\nspot_cut_off = np.pi / 8\nspot_light = rd.gui.create_spot_light(position, custom_material, direction, spot_exponent, spot_cut_off, intensity, attenuation_terms)\ngraphics.add_light(spot_light)\n</code></pre> <p>Directional Light:</p> C++Python <pre><code>// Create directional light\nMagnum::Vector3 direction = {-1.f, -1.f, -1.f};\nauto directional_light = robot_dart::gui::magnum::gs::create_directional_light(direction, custom_material);\ngraphics-&gt;add_light(directional_light);\n</code></pre> <pre><code># Create directional light\ndirection = magnum.Vector3(-1, -1, -1)\ndirectional_light = rd.gui.create_directional_light(direction, custom_material)\ngraphics.add_light(directional_light)\n</code></pre>"},{"location":"faq/#i-want-to-visualize-a-target-configuration-of-my-robot-is-this-possible","title":"I want to visualize a target configuration of my robot, is this possible?","text":"<p>Yes this is possible. RobotDART gives the ability to create a clone of your robot that has no physics, no contacts, just visuals:</p> C++Python <pre><code>// Add a ghost robot; only visuals, no dynamics, no collision\nauto ghost = robot-&gt;clone_ghost();\nsimu.add_robot(ghost);\n</code></pre> <pre><code># Add a ghost robot; only visuals, no dynamics, no collision\nghost = robot.clone_ghost()\nsimu.add_robot(ghost)\n</code></pre>"},{"location":"faq/#how-can-i-control-my-robot","title":"How can I control my robot ?","text":"<p>PD control</p> C++Python <pre><code>// add a PD-controller to the arm\n// set desired positions\nEigen::VectorXd ctrl = robot_dart::make_vector({0., M_PI / 4., 0., -M_PI / 4., 0., M_PI / 2., 0., 0.});\n// add the controller to the robot\nauto controller = std::make_shared&lt;robot_dart::control::PDControl&gt;(ctrl);\nrobot-&gt;add_controller(controller);\ncontroller-&gt;set_pd(300., 50.);\n</code></pre> <pre><code># add a PD-controller to the arm\n# set desired positions\nctrl = [0., np.pi / 4., 0., -np.pi / 4., 0., np.pi / 2., 0., 0.]\n# add the controller to the robot\ncontroller = rd.PDControl(ctrl)\nrobot.add_controller(controller)\ncontroller.set_pd(300., 50.)\n</code></pre> <p>Simple control</p> C++Python <pre><code>auto controller1 = std::make_shared&lt;robot_dart::control::SimpleControl&gt;(ctrl);\nrobot-&gt;add_controller(controller1);\n</code></pre> <pre><code>controller1 = rd.SimpleControl(ctrl)\nrobot.add_controller(controller1)\n</code></pre> <p>Robot control</p> C++Python <pre><code>class MyController : public robot_dart::control::RobotControl {\npublic:\nMyController() : robot_dart::control::RobotControl() {}\nMyController(const Eigen::VectorXd&amp; ctrl, bool full_control) : robot_dart::control::RobotControl(ctrl, full_control) {}\nMyController(const Eigen::VectorXd&amp; ctrl, const std::vector&lt;std::string&gt;&amp; dof_names) : robot_dart::control::RobotControl(ctrl, dof_names) {}\nvoid configure() override\n{\n_active = true;\n}\nEigen::VectorXd calculate(double) override\n{\nauto robot = _robot.lock();\nEigen::VectorXd cmd = 100. * (_ctrl - robot-&gt;positions(_controllable_dofs));\nreturn cmd;\n}\nstd::shared_ptr&lt;robot_dart::control::RobotControl&gt; clone() const override\n{\nreturn std::make_shared&lt;MyController&gt;(*this);\n}\n};\n</code></pre> <pre><code>class MyController(rd.RobotControl):\ndef __init__(self, ctrl, full_control):\nrd.RobotControl.__init__(self, ctrl, full_control)\ndef __init__(self, ctrl, controllable_dofs):\nrd.RobotControl.__init__(self, ctrl, controllable_dofs)\ndef configure(self):\nself._active = True\ndef calculate(self, t):\ntarget = np.array([self._ctrl])\ncmd = 100*(target-self.robot().positions(self._controllable_dofs))\nreturn cmd[0]\n# TO-DO: This is NOT working at the moment!\ndef clone(self):\nreturn MyController(self._ctrl, self._controllable_dofs)\n</code></pre>"},{"location":"faq/#is-there-a-way-to-control-the-simulation-timestep","title":"Is there a way to control the simulation timestep?","text":"<p>When creating a RobotDARTSimu object you choose the simulation timestep:</p> C++Python <pre><code>// choose time step of 0.001 seconds\nrobot_dart::RobotDARTSimu simu(0.001);\n</code></pre> <pre><code># choose time step of 0.001 seconds\nsimu = rd.RobotDARTSimu(0.001)\n</code></pre> <p>which can later be modified by:</p> C++Python <pre><code>// set timestep to 0.005 and update control frequency(bool)\nsimu.set_timestep(0.005, true);\n</code></pre> <pre><code># set timestep to 0.005 and update control frequency(bool)\nsimu.set_timestep(0.005, True)\n</code></pre>"},{"location":"faq/#i-want-to-simulate-a-mars-environment-is-it-possible-to-change-the-gravitational-force-of-the-simulation-environment","title":"I want to simulate a mars environment, is it possible to change the gravitational force of the simulation environment?","text":"<p>Yes you can modify the gravitational forces 3-dimensional vector of the simulation:</p> C++Python <pre><code>// Set gravitational force of mars\nEigen::Vector3d mars_gravity = {0., 0., -3.721};\nsimu.set_gravity(mars_gravity);\n</code></pre> <pre><code># set gravitational force of mars\nmars_gravity = [0., 0., -3.721]\nsimu.set_gravity(mars_gravity)\n</code></pre>"},{"location":"faq/#which-collision-detectors-are-available-what-are-their-differences-how-can-i-choose-between-them","title":"Which collision detectors are available? What are their differences? How can I choose between them?","text":"DART FCL ODE Bullet Support only basic shapes Full-featured collision detector fully integrated by DART External collision detector of ODE External collision detector of Bullet This is building along with DART This is a required dependency of DART Needs an external library Needs an external library Very fast for small scenes Accurate detailed collisions, but not very fast Fast collision detection (the integration is not complete) Fast and accurate collision detection (works well for wheels as well) <p>We can easily select one of the available collision detectors using the simulator object:</p> C++Python <pre><code>simu.set_collision_detector(\"fcl\"); // collision_detector can be \"dart\", \"fcl\", \"ode\" or \"bullet\" (case does not matter)\n</code></pre> <pre><code>simu.set_collision_detector(\"fcl\") # collision_detector can be \"dart\", \"fcl\", \"ode\" or \"bullet\" (case does not matter)\n</code></pre>"},{"location":"faq/#my-robot-does-not-self-collide-how-can-i-change-this","title":"My robot does not self-collide. How can I change this?","text":"<p>One possible cause may be the fact that self collision is disabled, you can check and change this:</p> C++Python <pre><code>if (!robot-&gt;self_colliding()) {\nstd::cout &lt;&lt; \"Self collision is not enabled\" &lt;&lt; std::endl;\n// set self collisions to true and adjacent collisions to false\nrobot-&gt;set_self_collision(true, false);\n}\n</code></pre> <pre><code>if(not robot.self_colliding()):\nprint(\"Self collision is not enabled\")\n# set self collisions to true and adjacent collisions to false\nrobot.set_self_collision(True, False)\n</code></pre>"},{"location":"faq/#how-can-i-compute-kinematicdynamic-properties-of-my-robot-eg-jacobians-mass-matrix","title":"How can I compute kinematic/dynamic properties of my robot (e.g., Jacobians, Mass Matrix)?","text":"<p>Kinematic Properties:</p> C++Python <pre><code>// Get Joint Positions(Angles)\nauto joint_positions = robot-&gt;positions();\n// Get Joint Velocities\nauto joint_vels = robot-&gt;velocities();\n// Get Joint Accelerations\nauto joint_accs = robot-&gt;accelerations();\n// Get link_name(str) Transformation matrix with respect to the world frame.\nauto eef_tf = robot-&gt;body_pose(link_name);\n// Get translation vector from transformation matrix\nauto eef_pos = eef_tf.translation();\n// Get rotation matrix from tranformation matrix\nauto eef_rot = eef_tf.rotation();\n// Get link_name 6d pose vector [logmap(eef_tf.linear()), eef_tf.translation()]\nauto eef_pose_vec = robot-&gt;body_pose_vec(link_name);\n// Get link_name 6d velocity vector [angular, cartesian]\nauto eef_vel = robot-&gt;body_velocity(link_name);\n// Get link_name 6d acceleration vector [angular, cartesian]\nauto eef_acc = robot-&gt;body_acceleration(link_name);\n// Jacobian targeting the origin of link_name(str)\nauto jacobian = robot-&gt;jacobian(link_name);\n// Jacobian time derivative\nauto jacobian_deriv = robot-&gt;jacobian_deriv(link_name);\n// Center of Mass Jacobian\nauto com_jacobian = robot-&gt;com_jacobian();\n// Center of Mass Jacobian Time Derivative\nauto com_jacobian_deriv = robot-&gt;com_jacobian_deriv();\n</code></pre> <pre><code># Get Joint Positions(Angles)\njoint_positions = robot.positions()\n# Get Joint Velocities\njoint_vels = robot.velocities()\n# Get Joint Accelerations\njoint_accs = robot.accelerations()\n# Get link_name(str) Transformation matrix with respect to the world frame.\neef_tf = robot.body_pose(link_name)\n# Get translation vector from transformation matrix\neef_pos = eef_tf.translation()\n# Get rotation matrix from tranformation matrix\neef_rot = eef_tf.rotation()\n# Get link_name 6d pose vector [logmap(eef_tf.linear()), eef_tf.translation()]\neef_pose_vec = robot.body_pose_vec(link_name)\n# Get link_name 6d velocity vector [angular, cartesian]\neef_vel = robot.body_velocity(link_name)\n# Get link_name 6d acceleration vector [angular, cartesian]\neef_acc = robot.body_acceleration(link_name)\n# Jacobian targeting the origin of link_name(str)\njacobian = robot.jacobian(link_name)\n# Jacobian time derivative\njacobian_deriv = robot.jacobian_deriv(link_name)\n# Center of Mass Jacobian\ncom_jacobian = robot.com_jacobian()\n# Center of Mass Jacobian Time Derivative\ncom_jacobian_deriv = robot.com_jacobian_deriv()\n</code></pre> <p>Dynamic Properties:</p> C++Python <pre><code>// Get Joint Forces\nauto joint_forces = robot-&gt;forces();\n// Get link's mass\nauto eef_mass = robot-&gt;body_mass(link_name);\n// Mass Matrix of robot\nauto mass_matrix = robot-&gt;mass_matrix();\n// Inverse of Mass Matrix\nauto inv_mass_matrix = robot-&gt;inv_mass_matrix();\n// Augmented Mass matrix\nauto aug_mass_matrix = robot-&gt;aug_mass_matrix();\n// Inverse of Augmented Mass matrix\nauto inv_aug_mass_matrix = robot-&gt;inv_aug_mass_matrix();\n// Coriolis Force vector\nauto coriolis = robot-&gt;coriolis_forces();\n// Gravity Force vector\nauto gravity = robot-&gt;gravity_forces();\n// Combined vector of Coriolis Force and Gravity Force\nauto coriolis_gravity = robot-&gt;coriolis_gravity_forces();\n// Constraint Force Vector\nauto constraint_forces = robot-&gt;constraint_forces();\n</code></pre> <pre><code># Get Joint Forces\njoint_forces = robot.forces()\n# Get link's mass\neef_mass = robot.body_mass(link_name)\n# Mass Matrix of robot\nmass_matrix = robot.mass_matrix()\n# Inverse of Mass Matrix\ninv_mass_matrix = robot.inv_mass_matrix()\n# Augmented Mass matrix\naug_mass_matrix = robot.aug_mass_matrix()\n# Inverse of Augmented Mass matrix\ninv_aug_mass_matrix = robot.inv_aug_mass_matrix()\n# Coriolis Force vector\ncoriolis = robot.coriolis_forces()\n# Gravity Force vector\ngravity = robot.gravity_forces()\n# Combined vector of Coriolis Force and Gravity Force\ncoriolis_gravity = robot.coriolis_gravity_forces()\n# NOT IMPLEMENTED\n# # Constraint Force Vector\n# constraint_forces = robot.constraint_forces()\n</code></pre>"},{"location":"faq/#is-there-a-way-to-change-the-joint-properties-eg-actuation-friction","title":"Is there a way to change the joint properties (e.g., actuation, friction)?","text":"<p>There are 6 types of actuators available, you can set the same actuator to multiple joints at once, or you can set each sensor separately:</p> C++Python <pre><code>// Set all DoFs to same actuator\nrobot-&gt;set_actuator_types(\"servo\"); // actuator types can be \"servo\", \"torque\", \"velocity\", \"passive\", \"locked\", \"mimic\"\n// You can also set actuator types separately\nrobot-&gt;set_actuator_type(\"torque\", \"iiwa_joint_5\");\n</code></pre> <pre><code># Set all DoFs to same actuator\n# actuator types can be \"servo\", \"torque\", \"velocity\", \"passive\", \"locked\", \"mimic\"\nrobot.set_actuator_types(\"servo\")\n# You can also set actuator types separately\nrobot.set_actuator_type(\"torque\", \"iiwa_joint_5\")\n</code></pre> <p>To enable position and velocity limits for the actuators:</p> C++Python <pre><code>// \u0395nforce joint position and velocity limits\nrobot-&gt;set_position_enforced(true);\n</code></pre> <pre><code># \u0395nforce joint position and velocity limits\nrobot.set_position_enforced(True)\n</code></pre> <p>Every DOF's limits (position, velocity, acceleration, force) can be modified:</p> C++Python <pre><code>// Modify Position Limits\nEigen::VectorXd pos_upper_lims(7);\npos_upper_lims &lt;&lt; 2.096, 2.096, 2.096, 2.096, 2.096, 2.096, 2.096;\nrobot-&gt;set_position_upper_limits(pos_upper_lims, dof_names);\nrobot-&gt;set_position_lower_limits(-pos_upper_lims, dof_names);\n// Modify Velocity Limits\nEigen::VectorXd vel_upper_lims(7);\nvel_upper_lims &lt;&lt; 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5;\nrobot-&gt;set_velocity_upper_limits(vel_upper_lims, dof_names);\nrobot-&gt;set_velocity_lower_limits(-vel_upper_lims, dof_names);\n// Modify Force Limits\nEigen::VectorXd force_upper_lims(7);\nforce_upper_lims &lt;&lt; 150, 150, 150, 150, 150, 150, 150;\nrobot-&gt;set_force_upper_limits(force_upper_lims, dof_names);\nrobot-&gt;set_force_lower_limits(-force_upper_lims, dof_names);\n// Modify Acceleration Limits\nEigen::VectorXd acc_upper_lims(7);\nacc_upper_lims &lt;&lt; 1500, 1500, 1500, 1500, 1500, 1500, 1500;\nrobot-&gt;set_acceleration_upper_limits(acc_upper_lims, dof_names);\nrobot-&gt;set_acceleration_lower_limits(-acc_upper_lims, dof_names);\n</code></pre> <pre><code># Modify Position Limits\npos_upper_lims = np.array([2.096, 2.096, 2.096, 2.096, 2.096, 2.096, 2.096])\nrobot.set_position_upper_limits(pos_upper_lims, dof_names)\nrobot.set_position_lower_limits(-1*pos_upper_lims, dof_names)\n# Modify Velocity Limits\nvel_upper_lims = np.array([1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5])\nrobot.set_velocity_upper_limits(vel_upper_lims, dof_names)\nrobot.set_velocity_lower_limits(-1*vel_upper_lims, dof_names)\n# Modify Force Limits\nforce_upper_lims = np.array([150, 150, 150, 150, 150, 150, 150])\nrobot.set_force_upper_limits(force_upper_lims, dof_names)\nrobot.set_force_lower_limits(-1*force_upper_lims, dof_names)\n# Modify Acceleration Limits\nacc_upper_lims = np.array([1500, 1500, 1500, 1500, 1500, 1500, 1500])\nrobot.set_acceleration_upper_limits(acc_upper_lims, dof_names)\nrobot.set_acceleration_lower_limits(-1*acc_upper_lims, dof_names)\n</code></pre> <p>You can also modify the damping coefficients, coulomb frictions and spring stiffness of every DOF:</p> C++Python <pre><code>// Modify Damping Coefficients\nstd::vector&lt;double&gt; damps = {0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4};\nrobot-&gt;set_damping_coeffs(damps, dof_names);\n// Modify Coulomb Frictions\nstd::vector&lt;double&gt; cfrictions = {0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001};\nrobot-&gt;set_coulomb_coeffs(cfrictions, dof_names);\n// Modify  Spring Stiffness\nstd::vector&lt;double&gt; stiffnesses = {0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001};\nrobot-&gt;set_spring_stiffnesses(stiffnesses, dof_names);\n</code></pre> <pre><code># Modify Damping Coefficients\ndamps = [0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4]\nrobot.set_damping_coeffs(damps, dof_names)\n# Modify Coulomb Frictions\ncfrictions = [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]\nrobot.set_coulomb_coeffs(cfrictions, dof_names)\n# Modify  Spring Stiffness\nstiffnesses = [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]\nrobot.set_spring_stiffnesses(stiffnesses, dof_names)\n</code></pre>"},{"location":"faq/#what-are-the-supported-sensors-how-can-i-use-an-imu","title":"What are the supported sensors? How can I use an IMU?","text":"<p>Sensors in RobotDART can be added only through the simulator object. All of the sensors can be added without being attached to any body or joint but some of them can operate only when attached to something (e.g. <code>ForceTorque</code> sensors).</p>"},{"location":"faq/#torque-sensor","title":"Torque sensor","text":"<p>Torque sensors can be added to every joint of the robot:</p> C++Python <pre><code>// Add torque sensors to the robot\nint ct = 0;\nstd::vector&lt;std::shared_ptr&lt;robot_dart::sensor::Torque&gt;&gt; tq_sensors(robot-&gt;num_dofs());\nfor (const auto&amp; joint : robot-&gt;dof_names())\ntq_sensors[ct++] = simu.add_sensor&lt;robot_dart::sensor::Torque&gt;(robot, joint, 1000);\n</code></pre> <pre><code># Add torque sensors to the robot\ntq_sensors = np.empty(robot.num_dofs(), dtype=rd.sensor.Torque)\nct = 0\nfor joint in robot.dof_names():\nsimu.add_sensor(rd.sensor.Torque(robot, joint, 1000))\ntq_sensors[ct] = simu.sensors()[-1]\nct += 1\n</code></pre> <p>Torque sensors measure the torque \\(\\tau \\in \\rm I\\!R^n\\) of the attached joint (where \\(n\\) is the DOFs of the joint):</p> C++Python <pre><code>// vector that contains the torque measurement for every joint (scalar)\nEigen::VectorXd torques_measure(robot-&gt;num_dofs());\nfor (const auto&amp; tq_sens : tq_sensors)\ntorques_measure.block&lt;1, 1&gt;(ct++, 0) = tq_sens-&gt;torques();\n</code></pre> <pre><code># vector that contains the torque measurement for every joint (scalar)\ntorques_measure = np.empty(robot.num_dofs())\nct = 0\nfor tq_sens in tq_sensors:\ntorques_measure[ct] = tq_sens.torques()\nct += 1\n</code></pre>"},{"location":"faq/#force-torque-sensor","title":"Force-Torque sensor","text":"<p>Force-Torque sensors can be added to every joint of the robot:</p> C++Python <pre><code>// Add force-torque sensors to the robot\nct = 0;\nstd::vector&lt;std::shared_ptr&lt;robot_dart::sensor::ForceTorque&gt;&gt; f_tq_sensors(robot-&gt;num_dofs());\nfor (const auto&amp; joint : robot-&gt;dof_names())\nf_tq_sensors[ct++] = simu.add_sensor&lt;robot_dart::sensor::ForceTorque&gt;(robot, joint, 1000, \"parent_to_child\");\n</code></pre> <pre><code># Add force-torque sensors to the robot\nf_tq_sensors = np.empty(robot.num_dofs(), dtype=rd.sensor.ForceTorque)\nct = 0\nfor joint in robot.dof_names():\nsimu.add_sensor(rd.sensor.ForceTorque(\nrobot, joint, 1000, \"parent_to_child\"))\nf_tq_sensors[ct] = simu.sensors()[-1]\nprint(f_tq_sensors)\nct += 1\n</code></pre> <p>Torque sensors measure the force \\(\\boldsymbol{F} \\in \\rm I\\!R^3\\), the torque \\(\\boldsymbol{\\tau} \\in \\rm I\\!R^3\\) and the wrench \\(\\boldsymbol{\\mathcal{F}} =\\begin{bmatrix} \\tau, F\\end{bmatrix}\\in \\rm I\\!R^6\\) of the attached joint:</p> C++Python <pre><code>//  matrix that contains the torque measurement for every joint (3d vector)\nEigen::MatrixXd ft_torques_measure(robot-&gt;num_dofs(), 3);\n//  matrix that contains the force measurement for every joint (3d vector)\nEigen::MatrixXd ft_forces_measure(robot-&gt;num_dofs(), 3);\n//  matrix that contains the wrench measurement for every joint (6d vector)[torque, force]\nEigen::MatrixXd ft_wrench_measure(robot-&gt;num_dofs(), 6);\nct = 0;\nfor (const auto&amp; f_tq_sens : f_tq_sensors) {\nft_torques_measure.block&lt;1, 3&gt;(ct, 0) = f_tq_sens-&gt;torque();\nft_forces_measure.block&lt;1, 3&gt;(ct, 0) = f_tq_sens-&gt;force();\nft_wrench_measure.block&lt;1, 6&gt;(ct, 0) = f_tq_sens-&gt;wrench();\nct++;\n}\n</code></pre> <pre><code>#  matrix that contains the torque measurement for every joint (3d vector)\nft_torques_measure = np.empty([robot.num_dofs(), 3])\n#  matrix that contains the force measurement for every joint (3d vector)\nft_forces_measure = np.empty([robot.num_dofs(), 3])\n#  matrix that contains the wrench measurement for every joint (6d vector)[torque, force]\nft_wrench_measure = np.empty([robot.num_dofs(), 6])\nct = 0\nfor f_tq_sens in f_tq_sensors:\nft_torques_measure[ct, :] = f_tq_sens.torque()\nft_forces_measure[ct, :] = f_tq_sens.force()\nft_wrench_measure[ct, :] = f_tq_sens.wrench()\nct += 1\n</code></pre>"},{"location":"faq/#imu-sensor","title":"IMU sensor","text":"<p>IMU sensors can be added to every link of the robot:</p> C++Python <pre><code>// Add IMU sensors to the robot\nct = 0;\nstd::vector&lt;std::shared_ptr&lt;robot_dart::sensor::IMU&gt;&gt; imu_sensors(robot-&gt;num_bodies());\nfor (const auto&amp; body_node : robot-&gt;body_names()) {\n// _imu(std::make_shared&lt;sensor::IMU&gt;(sensor::IMUConfig(body_node(\"head\"), frequency))),\nimu_sensors[ct++] = simu.add_sensor&lt;robot_dart::sensor::IMU&gt;(robot_dart::sensor::IMUConfig(robot-&gt;body_node(body_node), 1000));\n}\n</code></pre> <pre><code># Add IMU sensors to the robot\nct = 0\nimu_sensors = np.empty(robot.num_bodies(), dtype=rd.sensor.IMU)\nfor body_node in robot.body_names():\nsimu.add_sensor(rd.sensor.IMU(\nrd.sensor.IMUConfig(robot.body_node(body_node), 1000)))\nimu_sensors[ct] = simu.sensors()[-1]\nct += 1\n</code></pre> <p>IMU sensors measure the angular position vector \\(\\boldsymbol{\\theta} \\in \\rm I\\!R^3\\), the angular velocity \\(\\boldsymbol{\\omega} \\in \\rm I\\!R^3\\)  and the linear acceleration \\(\\boldsymbol{\\alpha} \\in \\rm I\\!R^3\\) of the attached link:</p> C++Python <pre><code>Eigen::MatrixXd imu_angular_positions_measure(robot-&gt;num_bodies(), 3);\nEigen::MatrixXd imu_angular_velocities_measure(robot-&gt;num_bodies(), 3);\nEigen::MatrixXd imu_linear_acceleration_measure(robot-&gt;num_bodies(), 3);\nct = 0;\nfor (const auto&amp; imu_sens : imu_sensors) {\nimu_angular_positions_measure.block&lt;1, 3&gt;(ct, 0) = imu_sens-&gt;angular_position_vec();\nimu_angular_velocities_measure.block&lt;1, 3&gt;(ct, 0) = imu_sens-&gt;angular_velocity();\nimu_linear_acceleration_measure.block&lt;1, 3&gt;(ct, 0) = imu_sens-&gt;linear_acceleration();\nct++;\n}\n</code></pre> <pre><code>imu_angular_positions_measure = np.empty([robot.num_bodies(), 3])\nimu_angular_velocities_measure = np.empty([robot.num_bodies(), 3])\nimu_linear_acceleration_measure = np.empty([robot.num_bodies(), 3])\nct = 0\nfor imu_sens in imu_sensors:\nimu_angular_positions_measure[ct,:] = imu_sens.angular_position_vec()\nimu_angular_velocities_measure[ct, :] = imu_sens.angular_velocity()\nimu_linear_acceleration_measure[ct,:] = imu_sens.linear_acceleration()\nct += 1\n</code></pre>"},{"location":"faq/#rgb-sensor","title":"RGB sensor","text":"<p>Any camera can be used as an RGB sensor:</p> C++Python <pre><code>// a nested std::vector (w*h*3) of the last image taken can be retrieved\nauto rgb_image = camera-&gt;image();\n</code></pre> <pre><code># a nested array (w*h*3) of the last image taken can be retrieved\nrgb_image = camera.image()\n</code></pre> <p>We can easily save the image and/or transform it to grayscale:</p> C++Python <pre><code>// a nested std::vector (w*h*3) of the last image taken can be retrieved\nauto rgb_image = camera-&gt;image();\n</code></pre> <pre><code># a nested array (w*h*3) of the last image taken can be retrieved\nrgb_image = camera.image()\n</code></pre>"},{"location":"faq/#rgb_d-sensor","title":"RGB_D sensor","text":"<p>Any camera can also be configured to also record depth:</p> C++Python <pre><code>camera-&gt;camera().record(true, true); // cameras are recording color images by default, enable depth images as well for this example\n</code></pre> <pre><code># cameras are recording color images by default, enable depth images as well for this example\ncamera.camera().record(True, True)\n</code></pre> <p>We can then read the RGB and depth images:</p> C++Python <pre><code>// get the depth image from a camera\n// with a version for visualization or bigger differences in the output\nauto rgb_d_image = camera-&gt;depth_image();\n// and the raw values that can be used along with the camera parameters to transform the image to point-cloud\nauto rgb_d_image_raw = camera-&gt;raw_depth_image();\n</code></pre> <pre><code># get the depth image from a camera\n# with a version for visualization or bigger differences in the output\nrgb_d_image = camera.depth_image()\n# and the raw values that can be used along with the camera parameters to transform the image to point-cloud\nrgb_d_image_raw = camera.raw_depth_image()\n</code></pre> <p>We can save the depth images as well:</p> C++Python <pre><code>robot_dart::gui::save_png_image(\"camera-depth.png\", rgb_d_image);\nrobot_dart::gui::save_png_image(\"camera-depth-raw.png\", rgb_d_image_raw);\n</code></pre> <pre><code>rd.gui.save_png_image(\"camera-depth.png\", rgb_d_image)\nrd.gui.save_png_image(\"camera-depth-raw.png\", rgb_d_image_raw)\n</code></pre>"},{"location":"faq/#how-can-i-spawn-multiple-robots-in-parallel","title":"How can I spawn multiple robots in parallel?","text":""},{"location":"faq/#robot-pool-only-in-c","title":"Robot Pool (only in C++)","text":"<p>The best way to do so is to create a Robot pool. With a robot pool you:</p> <ul> <li>Minimize the overhead of loading robots (it happens only once!) or cloning robots (it never happens)</li> <li>Make sure that your robots are \"clean\" once released from each thread</li> <li>Focus on the important stuff rather than handling robots and threads</li> </ul> <p>Let's see a more practical example:</p> <ul> <li>First we need to include the proper header:</li> </ul> C++ <pre><code>#include &lt;robot_dart/robot_pool.hpp&gt;\n</code></pre> <ul> <li>Then we create a <code>creator</code> function and the pool object:</li> </ul> C++ <pre><code>namespace pool {\n// This function should load one robot: here we load Talos\ninline std::shared_ptr&lt;robot_dart::Robot&gt; robot_creator()\n{\nreturn std::make_shared&lt;robot_dart::robots::Talos&gt;();\n}\n// To create the object we need to pass the robot_creator function and the number of maximum parallel threads\nrobot_dart::RobotPool robot_pool(robot_creator, NUM_THREADS);\n} // namespace pool\n</code></pre> <p>The <code>creator</code> function is the function responsible for loading your robot. This should basically look like a standalone code to load or create a robot.</p> <ul> <li>Next, we create a few threads that utilize the robots (in your code you might be using OpenMP or TBB):</li> </ul> C++ <pre><code>// for the example, we run NUM_THREADS threads of eval_robot()\nstd::vector&lt;std::thread&gt; threads(NUM_THREADS * 2); // *2 to see some reuse\nfor (size_t i = 0; i &lt; threads.size(); ++i)\nthreads[i] = std::thread(eval_robot, i); // eval_robot is the function that uses the robot\n</code></pre> <ul> <li>An example evaluation function:</li> </ul> C++ <pre><code>inline void eval_robot(int i)\n{\n// We get one available robot\nauto robot = pool::robot_pool.get_robot();\nstd::cout &lt;&lt; \"Robot \" &lt;&lt; i &lt;&lt; \" got [\" &lt;&lt; robot-&gt;skeleton() &lt;&lt; \"]\" &lt;&lt; std::endl;\n/// --- some robot_dart code ---\nsimulate_robot(robot);\n// --- do something with the result\nstd::cout &lt;&lt; \"End of simulation \" &lt;&lt; i &lt;&lt; std::endl;\n// CRITICAL : free your robot !\npool::robot_pool.free_robot(robot);\nstd::cout &lt;&lt; \"Robot \" &lt;&lt; i &lt;&lt; \" freed!\" &lt;&lt; std::endl;\n}\n</code></pre>"},{"location":"faq/#python","title":"Python","text":"<p>We have not implemented this feature in <code>Python</code> yet. One can emulate the <code>RobotPool</code> behavior or create a custom parallel robot loader.</p>"},{"location":"faq/#i-need-to-simulate-many-worlds-with-camera-sensors-in-parallel-how-can-i-do-this","title":"I need to simulate many worlds with camera sensors in parallel. How can I do this?","text":"<p>Below you can find an example showcasing the use of many worlds with camera sensors in parallel.</p> C++Python <pre><code>// Load robot from URDF\nauto global_robot = std::make_shared&lt;robot_dart::robots::Iiwa&gt;();\nstd::vector&lt;std::thread&gt; workers;\n// Set maximum number of parallel GL contexts (this is GPU-dependent)\nrobot_dart::gui::magnum::GlobalData::instance()-&gt;set_max_contexts(4);\n// We want 15 parallel simulations with different GL context each\nsize_t N_workers = 15;\nstd::mutex mutex;\nsize_t id = 0;\n// Launch the workers\nfor (size_t i = 0; i &lt; N_workers; i++) {\nworkers.push_back(std::thread([&amp;] {\nmutex.lock();\nsize_t index = id++;\nmutex.unlock();\n// Get the GL context -- this is a blocking call\n// will wait until one GL context is available\n// get_gl_context(gl_context); // this call will not sleep between failed queries\nget_gl_context_with_sleep(gl_context, 20); // this call will sleep 20ms between each failed query\n// Do the simulation\nauto robot = global_robot-&gt;clone();\nrobot_dart::RobotDARTSimu simu(0.001);\nEigen::VectorXd ctrl = robot_dart::make_vector({0., M_PI / 3., 0., -M_PI / 4., 0., 0., 0.});\nauto controller = std::make_shared&lt;robot_dart::control::PDControl&gt;(ctrl);\nrobot-&gt;add_controller(controller);\ncontroller-&gt;set_pd(300., 50.);\n// Magnum graphics\nrobot_dart::gui::magnum::GraphicsConfiguration configuration = robot_dart::gui::magnum::WindowlessGraphics::default_configuration();\nconfiguration.width = 1024;\nconfiguration.height = 768;\nauto graphics = std::make_shared&lt;robot_dart::gui::magnum::WindowlessGraphics&gt;(configuration);\nsimu.set_graphics(graphics);\n// Position the camera differently for each thread to visualize the difference\ngraphics-&gt;look_at({0.4 * index, 3.5 - index * 0.1, 2.}, {0., 0., 0.25});\n// record images from main camera/graphics\n// graphics-&gt;set_recording(true); // WindowlessGLApplication records images by default\nsimu.add_robot(robot);\nsimu.run(6);\n// Save the image for verification\nrobot_dart::gui::save_png_image(\"camera_\" + std::to_string(index) + \".png\",\ngraphics-&gt;image());\n// Release the GL context for another thread to use\nrelease_gl_context(gl_context);\n}));\n}\n// Wait for all the workers\nfor (size_t i = 0; i &lt; workers.size(); i++) {\nworkers[i].join();\n}\n</code></pre> <pre><code>robot = rd.Robot(\"arm.urdf\", \"arm\", False)\nrobot.fix_to_world()\ndef test():\npid = os.getpid()\nii = pid%15\n# create the controller\npdcontrol = rd.PDControl([0.0, 1.0, -1.5, 1.0], False)\n# clone the robot\ngrobot = robot.clone()\n# add the controller to the robot\ngrobot.add_controller(pdcontrol, 1.)\npdcontrol.set_pd(200., 20.)\n# create the simulation object\nsimu = rd.RobotDARTSimu(0.001)\n# set the graphics\ngraphics = rd.gui.WindowlessGraphics()\nsimu.set_graphics(graphics)\ngraphics.look_at([0.4 * ii, 3.5 - ii * 0.1, 2.], [0., 0., 0.25], [0., 0., 1.])\n# add the robot and the floor\nsimu.add_robot(grobot)\nsimu.add_checkerboard_floor()\n# run\nsimu.run(20.)\n# save last frame for visualization purposes\nimg = graphics.image()\nrd.gui.save_png_image('camera-' + str(ii) + '.png', img)\n# helper function to run in parallel\ndef runInParallel(N):\nproc = []\nfor i in range(N):\n# rd.gui.run_with_gl_context accepts 2 parameters:\n#    (func, wait_time_in_ms)\n#    the func needs to be of the following format: void(), aka no return, no arguments\np = Process(target=rd.gui.run_with_gl_context, args=(test, 20))\np.start()\nproc.append(p)\nfor p in proc:\np.join()\nprint('Running parallel evaluations')\nN = 15\nstart = timer()\nrunInParallel(N)\nend = timer()\nprint('Time:', end-start)\n</code></pre> <p>In C++ you are also able to pre-allocate a custom number of OpenGL contexts so that you can take advantage of stronger GPUs.</p>"},{"location":"faq/#i-do-not-know-how-to-use-waf-how-can-i-detect-robotdart-from-cmake","title":"I do not know how to use waf. How can I detect RobotDART from CMake?","text":"<p>You need to use <code>waf</code> to build RobotDART, but when installing the library a CMake module is installed. Thus it is possible use RobotDART in your code using CMake. You can find a complete example at cmake/example. In short the CMake would look like this:</p> <pre><code>cmake_minimum_required(VERSION 3.10 FATAL_ERROR)\nproject(robot_dart_example)\n# we ask for Magnum because we want to build the graphics\nfind_package(RobotDART REQUIRED OPTIONAL_COMPONENTS Magnum)\nadd_executable(robot_dart_example example.cpp)\ntarget_link_libraries(robot_dart_example\nRobotDART::Simu\n)\nif(RobotDART_Magnum_FOUND)\nadd_executable(robot_dart_example_graphics example.cpp)\ntarget_link_libraries(robot_dart_example_graphics\nRobotDART::Simu\nRobotDART::Magnum\n)\nendif()\n</code></pre>"},{"location":"faq/#where-can-i-find-complete-working-examples-for-either-c-or-python","title":"Where can I find complete working examples for either c++ or python?","text":"<p>C++ examples</p> <p>Python examples</p>"},{"location":"install/","title":"Manual Installation","text":""},{"location":"install/#manual-installation-of-robotdart","title":"Manual Installation of RobotDART","text":"<p>For the quick installation manual, see the quick installation page.</p>"},{"location":"install/#dependencies","title":"Dependencies","text":""},{"location":"install/#required","title":"Required","text":"<ul> <li>Ubuntu (it should work on versions &gt;= 14.04) or OSX</li> <li>Eigen3</li> <li>DART, http://dartsim.github.io/</li> </ul>"},{"location":"install/#optional","title":"Optional","text":"<ul> <li>Boost (for unit tests)</li> <li>Magnum (for graphics), https://github.com/mosra/magnum</li> </ul>"},{"location":"install/#installation-of-the-dependencies","title":"Installation of the dependencies","text":"<p>Note: The following instructions are high-level and assume people with some experience in building/installing software.</p>"},{"location":"install/#installing-system-wide-packages","title":"Installing system-wide packages","text":"<p>For Ubuntu-based distributions (&gt;=20.04) we should use the following commands:</p> <pre><code>sudo apt-get update\nsudo apt-get install build-essential cmake pkg-config git libboost-regex-dev libboost-system-dev libboost-test-dev pybind11-dev\nsudo apt-get install libdart-all-dev\n</code></pre> <p>For OSX with brew:</p> <pre><code>brew install dartsim\n</code></pre>"},{"location":"install/#installing-magnum","title":"Installing Magnum","text":"<p>Magnum depends on Corrade and we are going to use a few plugins and extras from the library. We are also going to use Glfw and Glx for the back-end. Follow the instrutions below:</p> <pre><code>#installation of Glfw and OpenAL\n# Ubuntu\nsudo apt-get install libglfw3-dev libglfw3 libassimp-dev libopenal-dev libglfw3-dev libsdl2-dev libopenexr-dev libdevil-dev libpng-dev libfaad-dev libfreetype6-dev\n# Mac OSX\nbrew install glfw3 openal-soft assimp\n\n# installation of Corrade\ncd /path/to/tmp/folder\ngit clone https://github.com/mosra/corrade.git\ncd corrade\nmkdir build &amp;&amp; cd build\ncmake -DCMAKE_BUILD_TYPE=Release ..\nmake -j\nsudo make install\n\n# installation of Magnum\ncd /path/to/tmp/folder\ngit clone https://github.com/mosra/magnum.git\ncd magnum\nmkdir build &amp;&amp; cd build\n# Ubuntu\ncmake -DCMAKE_BUILD_TYPE=Release -DWITH_AUDIO=ON -DWITH_DEBUGTOOLS=ON -DWITH_GL=ON -DWITH_MESHTOOLS=ON -DWITH_PRIMITIVES=ON -DWITH_SCENEGRAPH=ON -DWITH_SHADERS=ON -DWITH_TEXT=ON -DWITH_TEXTURETOOLS=ON -DWITH_TRADE=ON -DWITH_GLFWAPPLICATION=ON -DWITH_WINDOWLESSEGLAPPLICATION=ON -DWITH_OPENGLTESTER=ON -DWITH_ANYAUDIOIMPORTER=ON -DWITH_ANYIMAGECONVERTER=ON -DWITH_ANYIMAGEIMPORTER=ON -DWITH_ANYSCENEIMPORTER=ON -DWITH_MAGNUMFONT=ON -DWITH_OBJIMPORTER=ON -DWITH_TGAIMPORTER=ON -DWITH_WAVAUDIOIMPORTER=ON -DTARGET_EGL=ON .. # this will enable almost all features of Magnum that are not necessarily needed for robot_dart (please refer to the documentation of Magnum for more details on selecting only the ones that you need)\n# Mac OSX\ncmake -DCMAKE_BUILD_TYPE=Release -DWITH_AUDIO=ON -DWITH_DEBUGTOOLS=ON -DWITH_GL=ON -DWITH_MESHTOOLS=ON -DWITH_PRIMITIVES=ON -DWITH_SCENEGRAPH=ON -DWITH_SHADERS=ON -DWITH_TEXT=ON -DWITH_TEXTURETOOLS=ON -DWITH_TRADE=ON -DWITH_GLFWAPPLICATION=ON -DWITH_WINDOWLESSCGLAPPLICATION=ON -DWITH_OPENGLTESTER=ON -DWITH_ANYAUDIOIMPORTER=ON -DWITH_ANYIMAGECONVERTER=ON -DWITH_ANYIMAGEIMPORTER=ON -DWITH_ANYSCENEIMPORTER=ON -DWITH_MAGNUMFONT=ON -DWITH_OBJIMPORTER=ON -DWITH_TGAIMPORTER=ON -DWITH_WAVAUDIOIMPORTER=ON .. # this will enable almost all features of Magnum that are not necessarily needed for robot_dart (please refer to the documentation of Magnum for more details on selecting only the ones that you need)\nmake -j\nsudo make install\n\n# installation of Magnum Plugins\ncd /path/to/tmp/folder\ngit clone https://github.com/mosra/magnum-plugins.git\ncd magnum-plugins\nmkdir build &amp;&amp; cd build\ncmake -DCMAKE_BUILD_TYPE=Release -DWITH_ASSIMPIMPORTER=ON -DWITH_DDSIMPORTER=ON -DWITH_JPEGIMPORTER=ON -DWITH_OPENGEXIMPORTER=ON -DWITH_PNGIMPORTER=ON -DWITH_TINYGLTFIMPORTER=ON -DWITH_STBTRUETYPEFONT=ON .. # this will enable quite a few Magnum Plugins that are not necessarily needed for robot_dart (please refer to the documentation of Magnum for more details on selecting only the ones that you need)\nmake -j\nsudo make install\n\n# installation of Magnum DART Integration (DART needs to be installed) and Eigen Integration\ncd /path/to/tmp/folder\ngit clone https://github.com/mosra/magnum-integration.git\ncd magnum-integration\nmkdir build &amp;&amp; cd build\ncmake -DCMAKE_BUILD_TYPE=Release -DWITH_DART=ON -DWITH_EIGEN=ON ..\nmake -j\nsudo make install\n</code></pre>"},{"location":"install/#compilation-and-running-the-examples","title":"Compilation and running the examples","text":"<p>The compilation of the library is straight-forward:</p> <ul> <li>retrieve the code, for instance with <code>git clone https://github.com/resibots/robot_dart.git</code></li> <li><code>cd /path/to/repo/root</code></li> <li><code>./waf configure</code></li> <li><code>./waf</code></li> </ul> <p>To build the examples, execute this: <code>./waf examples</code></p> <p>Now you can run the examples. For example, to run the arm example you need to type the following: <code>./build/arm</code> (or <code>./build/arm_plain</code> to run it without graphics).</p>"},{"location":"install/#installing-the-library","title":"Installing the library","text":"<p>To install the library (assuming that you have already compiled it), you need only to run:</p> <ul> <li><code>./waf install</code></li> </ul> <p>By default the library will be installed in <code>/usr/local/lib</code> (for this maybe <code>sudo ./waf install</code> might be needed) and a static library will be generated. You can change the defaults as follows:</p> <ul> <li><code>./waf configure --prefix=/path/to/install/dir --shared</code></li> <li><code>./waf install</code></li> </ul> <p>In short, with <code>--prefix</code> you can change the directory where the library will be installed and if <code>--shared</code> is present a shared library will be created instead of a static one.</p>"},{"location":"install/#compiling-the-python-bindings","title":"Compiling the python bindings","text":"<p>For the python bindings of robot_dart, we need <code>numpy</code> to be installed, <code>pybind11</code> and the python bindings of DART (dartpy).</p> <p>For <code>numpy</code> one can install it with <code>pip</code> or standard packages. <code>dartpy</code> should be installed via the packages above. If not, please see the installation instructions on the main DART website.</p> <p>Then the compilation of robot_dart is almost identical as before:</p> <ul> <li>retrieve the code, for instance with <code>git clone https://github.com/resibots/robot_dart.git</code></li> <li><code>cd /path/to/repo/root</code></li> <li><code>./waf configure --python</code> (<code>--python</code> enables the python bindings)</li> <li><code>./waf</code></li> <li>Install the library (including the python bindings) as before (no change is needed)</li> <li>Depending on your installation directory you might need to update your <code>PYTHONPATH</code>, e.g. <code>export PYTHONPATH=$PYTHONPATH:/usr/local/lib/python3.10/site-packages/</code></li> </ul> <p>To run the python examples (for the python examples you need to have enabled the graphics, that is, install Magnum library), run:</p> <ul> <li><code>cd /path/to/repo/root</code></li> <li><code>python src/python/example.py</code> or <code>python src/python/example_parallel.py</code></li> </ul>"},{"location":"install/#common-issues-with-python-bindings","title":"Common Issues with Python bindings","text":"<p>One of the most common issue with the python bindings is the fact that DART bindings might be compiled and installed for python 3 and the robot_dart ones for python 2. To force the usage of python 3 for robot_dart, you use <code>python3 ./waf</code> instead of just <code>./waf</code> in all the commands above.</p>"},{"location":"quick_install/","title":"Installation","text":""},{"location":"quick_install/#scripts-for-quick-installation-of-robotdart","title":"Scripts for Quick Installation of RobotDART","text":"<p>In this page we provide standalone scripts for installing RobotDART for <code>Ubuntu</code> (&gt;=20.04) and <code>OSX</code>. The scripts will install all the required dependencies and RobotDART. Notably, all dependencies that need to be compiled by source and RobotDART will be installed inside the <code>/opt</code> folder. This way, one can be rest assured that their system will be clean.</p>"},{"location":"quick_install/#ubuntu-2004","title":"Ubuntu &gt;=20.04","text":"<p>To quickly install RobotDART on <code>Ubuntu &gt;=20.04</code>, we just need to run <code>./scripts/install_ubuntu.sh</code> from the root of the repo. In more detail:</p> <ul> <li><code>git clone https://github.com/resibots/robot_dart.git</code></li> <li><code>cd robot_dart</code></li> <li><code>./scripts/install_ubuntu.sh</code></li> </ul> <p>This will install everything needed! Once the script is successfully executed, one should add the following to their <code>~/.bashrc</code> or <code>~/.zshrc</code> file (you may need to swap the python version to yours1):</p> <pre><code>export PATH=/opt/magnum/bin:$PATH\nexport LD_LIBRARY_PATH=/opt/magnum/lib:/opt/robot_dart/lib:$LD_LIBRARY_PATH\nexport PYTHONPATH=/opt/robot_dart/lib/python3.10/site-packages:$PYTHONPATH\n</code></pre>"},{"location":"quick_install/#osx","title":"OSX","text":"<p>Coming soon</p> <ol> <li> <p>You can run <code>python --version</code> to see your version. We only keep the major.minor (ignoring the patch version)\u00a0\u21a9</p> </li> </ol>"},{"location":"robots/","title":"Supported robots","text":""},{"location":"robots/#supported-robots","title":"Supported robots","text":"<p>Every robot is a defined as a URDF, which will be installed <code>$PREFIX/share/utheque</code>. All robots have pre-defined \"robot classes\" that define sensors and other properties; for your custom/new robots, you will have to add the sensors/properties via the generic robot class (or create a new robot class).</p> <p>The URDF files are loaded using the following rules (see <code>utheque::path()</code>):</p> <ul> <li>First check in the current directory</li> <li>If not found, check in <code>current_directory/utheque</code></li> <li>If not found, check in <code>$ROBOT_DART_PATH/utheque</code></li> <li>If not found, check in the robot dart installation path/robots (e.g., <code>/usr/share/utheque</code> or <code>$HOME/share/utheque</code>)</li> <li>Otherwise, report failure</li> </ul> <p><code>utheque</code> is a separate header-only library that gets installed together with RobotDART (or even alone), that can be used in libraries that do not want to interfere with RobotDART and use the curated URDF files.</p>"},{"location":"robots/#talos-pal-robotics","title":"Talos (PAL Robotics)","text":"<p>Talos is a humanoid robot made by PAL Robotics.</p> <ul> <li>Datasheet: [pdf]</li> <li>32 degrees of freedom (6 for each leg, 7 for each arm, 2 for the waist, 2 for the neck, 1 for each gripper)</li> <li>175 cm / 95 kg</li> <li>IMU in the torso</li> <li>Torque sensors in all joints except head, wrist and gripper (22 torque sensors total)</li> <li>1 force/torque sensor in each ankle</li> <li>1 force/torque sensor in each wrist</li> </ul> <p>We have two URDF files:</p> <ul> <li><code>robots/talos/talos.urdf</code> :<ul> <li>accurate (simplified but made of polygons) collision meshes</li> <li>mimic joints for the gripper</li> <li>Not compatible the DART collision detector (you need to use FCL collision detector - shipped with DART)</li> <li>URDF: [talos.urdf]</li> <li>Example: [talos.cpp]</li> </ul> </li> </ul> <p>Load Talos</p> C++ <pre><code>auto robot = std::make_shared&lt;robot_dart::robots::Talos&gt;();\n</code></pre> Python <pre><code>robot = rd.Talos()\n</code></pre> <ul> <li><code>robot/talos/talos_fast.urdf</code>:<ul> <li>no collision except for the feet, which are approximated by boxes</li> <li>grippers are fixed (no movement is allowed)</li> <li>compatible with the DART collision detector</li> <li>URDF: [talos_fast.urdf]</li> <li>Example: [talos_fast.cpp]</li> </ul> </li> </ul> <p><code>talos_fast.urdf</code> is faster because it makes it possible to use the DART collision detector (and has much collision shapes). You should prefer it except if you want to use the grippers (e.g., for manipulation) or are working on self-collisions.</p> <p>Load Talos Fast</p> C++ <pre><code>// load talos fast\nauto robot = std::make_shared&lt;robot_dart::robots::TalosFastCollision&gt;();\n// Set actuator types to VELOCITY (for speed)\nrobot-&gt;set_actuator_types(\"velocity\");\ndouble dt = 0.001;\nrobot_dart::RobotDARTSimu simu(dt);\n// we can use the DART (fast) collision detector\nsimu.set_collision_detector(\"dart\");\n</code></pre> Python <pre><code>robot = rd.TalosFastCollision()\n</code></pre> <p>Please note that the mesh files (.glb) require assimp 5.x (and not assimp4.x usually shipped with ROS). If you cannot load the URDF, please check your assimp version.</p>"},{"location":"robots/#panda-franka-emika","title":"Panda (Franka Emika)","text":"<p>The Franka is a modern manipulator made by Franka Emika Panda. It is commonly found in many robotics labs.</p> <ul> <li>Datasheet: [pdf]</li> <li>7 degrees of freedom</li> <li>Can be controlled in torque</li> <li>18 kg</li> <li>workspace: 855 mm (horizontal), 1190 mm (vertical)</li> <li>URDF: [franka.urdf]</li> <li>Example: [franka.cpp] The URDF includes the gripper.</li> </ul> <p>Load Franka</p> C++ <pre><code>auto robot = std::make_shared&lt;robot_dart::robots::Franka&gt;();\n</code></pre> Python <pre><code>robot = rd.Franka()\n</code></pre>"},{"location":"robots/#lbr-iiwa-kuka","title":"LBR iiwa (KUKA)","text":"<p>The LBR iiwa is manufactured by KUKA. It is similar to the Panda and is also very common in robotics labs.</p> <ul> <li>Datasheet: [pdf]</li> <li>We implement the 14 kg version</li> <li>29.5 kg</li> <li>7 degrees of freedom</li> <li>URDF: [iiwa.urdf]</li> <li>Example: [iiwa.cpp]</li> </ul> <p>Load Iiwa</p> C++ <pre><code>auto robot = std::make_shared&lt;robot_dart::robots::Iiwa&gt;();\n</code></pre> Python <pre><code>robot = rd.Iiwa()\n</code></pre>"},{"location":"robots/#icub-iit","title":"iCub (IIT)","text":"<p>The iCub is a open source humanoid robot made by the Instituto Italiano di Tecnologia. There are currently 42 iCUbs in the world, and many versions.</p> <ul> <li>Datasheet (rev 2.3) [pdf]</li> <li>6 force/torque sensors (upper arms, upper legs, ankles)</li> <li>IMU in the head</li> <li>We do to simulate the skin</li> <li>We do not simulate the hands</li> <li>Our model is close to the Inria's iCub, but it has not been checked in detail.</li> <li>URDF: [icub.urdf]</li> <li>Example [icub.cpp]</li> </ul> <p>Please note that the mesh files (.glb) require assimp 5.x (and not assimp4.x usually shipped with ROS). If you cannot load the URDF, please check your assimp version.</p> <p>Load iCub</p> C++ <pre><code>auto robot = std::make_shared&lt;robot_dart::robots::ICub&gt;();\n// Set actuator types to VELOCITY motors so that they stay in position without any controller\nrobot-&gt;set_actuator_types(\"velocity\");\nrobot_dart::RobotDARTSimu simu(0.001);\nsimu.set_collision_detector(\"fcl\");\n</code></pre> Python <pre><code>robot = rd.ICub()\n# Set actuator types to VELOCITY motors so that they stay in position without any controller\nrobot.set_actuator_types(\"velocity\")\nsimu = rd.RobotDARTSimu(0.001)\nsimu.set_collision_detector(\"fcl\")\n</code></pre> <p>Print IMU sensor measurements</p> C++ <pre><code>std::cout &lt;&lt; \"Angular    Position: \" &lt;&lt; robot-&gt;imu().angular_position_vec().transpose().format(fmt) &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"Angular    Velocity: \" &lt;&lt; robot-&gt;imu().angular_velocity().transpose().format(fmt) &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"Linear Acceleration: \" &lt;&lt; robot-&gt;imu().linear_acceleration().transpose().format(fmt) &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"=================================\" &lt;&lt; std::endl;\n</code></pre> Python <pre><code>print(\"Angular    Position: \",  robot.imu().angular_position_vec().transpose())\nprint(\"Angular    Velocity: \",  robot.imu().angular_velocity().transpose())\nprint(\"Linear Acceleration: \",  robot.imu().linear_acceleration().transpose())\nprint(\"=================================\" )\n</code></pre> <p>Print Force-Torque sensor measurements</p> C++ <pre><code>std::cout &lt;&lt; \"FT ( force): \" &lt;&lt; robot-&gt;ft_foot_left().force().transpose().format(fmt) &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"FT (torque): \" &lt;&lt; robot-&gt;ft_foot_left().torque().transpose().format(fmt) &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"=================================\" &lt;&lt; std::endl;\n</code></pre> Python <pre><code>print(\"FT ( force): \",  robot.ft_foot_left().force().transpose())\nprint(\"FT (torque): \",  robot.ft_foot_left().torque().transpose())\nprint(\"=================================\")\n</code></pre>"},{"location":"robots/#unitree-a1","title":"Unitree A1","text":"<p>A1 is a quadruped robot made by the Unitree Robotics.</p> <ul> <li>IMU in the torso</li> <li>We do not simulate the foot pressure sensors (yet)</li> <li>One can easily add a depth camera on the head</li> <li>URDF: [a1.urdf]</li> <li>Example [a1.cpp]</li> </ul> <p>Load A1</p> C++ <pre><code>auto robot = std::make_shared&lt;robot_dart::robots::A1&gt;();\n</code></pre> Python <pre><code>robot = rd.A1()\n</code></pre> <p>Print IMU sensor measurements</p> C++ <pre><code>std::cout &lt;&lt; \"Angular    Position: \" &lt;&lt; robot-&gt;imu().angular_position_vec().transpose().format(fmt) &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"Angular    Velocity: \" &lt;&lt; robot-&gt;imu().angular_velocity().transpose().format(fmt) &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"Linear Acceleration: \" &lt;&lt; robot-&gt;imu().linear_acceleration().transpose().format(fmt) &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"=================================\" &lt;&lt; std::endl;\n</code></pre> Python <pre><code>print( \"Angular    Position: \", robot.imu().angular_position_vec().transpose())\nprint( \"Angular    Velocity: \", robot.imu().angular_velocity().transpose())\nprint( \"Linear Acceleration: \", robot.imu().linear_acceleration().transpose())\nprint( \"=================================\")\n</code></pre> <p>Add a depth camera on the head</p> <p>How can I attach a camera to a moving link?</p> <p>Please note that the mesh files (.glb) require assimp 5.x (and not assimp4.x usually shipped with ROS). If you cannot load the URDF, please check your assimp version.</p>"},{"location":"robots/#dynamixel-based-hexapod-robot-inria-and-others","title":"Dynamixel-based hexapod robot (Inria and others)","text":"<p>This hexapod is a simple 6-legged robot based on dynamixel actuators. It is similar to the robot used in the paper `Robots that can adapt like animals' (Cully et al., 2015).</p> <ul> <li>6 legs, 3 degrees of freedom for each leg (18 degrees of freedom)</li> <li>simple URDF (no meshes)</li> <li>URDF: [pexod.urdf]</li> <li>Example: [hexapod.cpp]</li> </ul> <p>Load Hexapod</p> C++ <pre><code>auto robot = std::make_shared&lt;robot_dart::robots::Hexapod&gt;();\n</code></pre> Python <pre><code>robot = rd.Hexapod()\n</code></pre> <p>Load Pexod</p> C++ <pre><code>auto robot = std::make_shared&lt;robot_dart::Robot&gt;(\"pexod.urdf\");\n</code></pre> Python <pre><code>robot = rd.Robot(\"pexod.urdf\");\n</code></pre>"},{"location":"robots/#simple-arm","title":"Simple arm","text":"<ul> <li>A simple arm for educational or debugging purposes</li> <li>5 degrees of freedom</li> <li>simple URDF (no meshes)</li> <li>URDF: [arm.urdf]</li> <li>Example: [arm.cpp]</li> </ul> <p>Load Simple Arm</p> C++ <pre><code>auto robot = std::make_shared&lt;robot_dart::robots::Arm&gt;();\n</code></pre> Python <pre><code>robot = rd.Arm()\n</code></pre>"},{"location":"robots/#loading-custom-robots","title":"Loading Custom Robots","text":"<p>RobotDART gives you the ability to load custom robots  that are defined in URDF, SDF, SKEL or MJCF files. For example, you can load a urdf model using:</p> <p>Load custom Robot</p> C++ <pre><code>    auto your_robot = std::make_shared&lt;robot_dart::Robot&gt;(\"path/to/model.urdf\");\n</code></pre> Python <pre><code>    your_robot = robot_dart.Robot(\"path/to/model.urdf\")\n</code></pre> <p>Load custom Robot with packages (e.g STL, DAE meshes)</p> C++ <pre><code>    std::vector&lt;std::pair&lt;std::string, std::string&gt;&gt; your_model_packages = ('model', 'path/to/model/dir');\nauto your_robot = std::make_shared&lt;robot_dart::Robot&gt;(\"path/to/model.urdf\", your_model_packages, \"packages\");\n</code></pre> Python <pre><code>    your_model_packages = [(\"model\", \"path/to/model/dir\")]\nyour_robot = robot_dart.Robot(\"path/to/model.urdf\", your_model_packages)\n</code></pre>"}]}