{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":".md-typeset h1, .md-content__button { display: none; } RobotDART \u00b6 RobotDART is a C++11 robot simulator (with optional Python bindings) built on top of the DART physics engine. The RobotDART simulator is intended to be used by Robotics and Machine Learning researchers who want to write controllers or test learning algorithms without the delays and overhead that usually comes with other simulators (e.g., Gazebo , Coppelia-sim ). For this reason, the simulator runs headless by default , and there is the possibility of rendering the scene (e.g., through a camera sensor) without opening a graphics window . All RobotDART's code is thread-safe (including graphics and camera sensors ), and thus enables its users to use their code in parallel jobs in multicore computers . In a few words, RobotDART combines: a physics engine (DART) an optional graphics engine (Magnum) a few sensor classes (IMU, force/torque sensors, cameras, etc.) a curated URDF library ... and a few useful features to make the life of roboticists/researchers easier Main Features \u00b6 Modern C++ code that makes it easy to develop environments and applications Fast and reliable simulation of robotic mechanisms and their interactions (through the DART physics engine) A structured Robot class that enables a unified creation and access to all important values: in RobotDART you can load any robot description file (URDF, SDF, SKEL, and MuJoCo files) with the same command, and all robot measurements can be queried without using any DART code A generic RobotControl class that enables fast prototyping of any type of controller A generic Sensor class that allows the creation of any kind of sensor A growing list of already implemented sensors , that includes 6-axis ForceTorque , IMU , RGB , and RGB-D sensors A simulation class ( RobotDARTSimu ) that handles multiple robots and sensors, and allows for step-by-step simulation A growing list of supported robots along with edited and optimized models to be used with RobotDART (see the robots page for details and examples): PAL Talos humanoid Franka Emika Panda KUKA LBR Iiwa (14kg version) IIT iCub humanoid (without hands) Unitree A1 quadruped robot Dynamixel-based 6-legged robot A simple arm for educational purposes and you can use any URDF A custom graphical interface built on top of Magnum that allows generic customization Support for windowless OpenGL context creation (even in parallel threads!) to allow for camera sensor usage even in parallel jobs running on clusters Support for video recording in simulation time (i.e., not affected by delays of simulator and/or graphics) for visualization or debugging purposes Full-featured Python bindings for fast prototyping RobotDART runs on any Linux distribution and Mac OS What RobotDART is not \u00b6 RobotDART is primarily intended to be non-interactive (run a simulation, record/view the result), Interaction is limited to changing the view and your own code. No GUI for adding objects or interactively build an environment, RobotDART is not optimized for wheeled robots, RobotDART is not optimized for simulating complex (e.g., mountain-like) terrains.","title":"Home"},{"location":"#robotdart","text":"RobotDART is a C++11 robot simulator (with optional Python bindings) built on top of the DART physics engine. The RobotDART simulator is intended to be used by Robotics and Machine Learning researchers who want to write controllers or test learning algorithms without the delays and overhead that usually comes with other simulators (e.g., Gazebo , Coppelia-sim ). For this reason, the simulator runs headless by default , and there is the possibility of rendering the scene (e.g., through a camera sensor) without opening a graphics window . All RobotDART's code is thread-safe (including graphics and camera sensors ), and thus enables its users to use their code in parallel jobs in multicore computers . In a few words, RobotDART combines: a physics engine (DART) an optional graphics engine (Magnum) a few sensor classes (IMU, force/torque sensors, cameras, etc.) a curated URDF library ... and a few useful features to make the life of roboticists/researchers easier","title":"RobotDART"},{"location":"#main-features","text":"Modern C++ code that makes it easy to develop environments and applications Fast and reliable simulation of robotic mechanisms and their interactions (through the DART physics engine) A structured Robot class that enables a unified creation and access to all important values: in RobotDART you can load any robot description file (URDF, SDF, SKEL, and MuJoCo files) with the same command, and all robot measurements can be queried without using any DART code A generic RobotControl class that enables fast prototyping of any type of controller A generic Sensor class that allows the creation of any kind of sensor A growing list of already implemented sensors , that includes 6-axis ForceTorque , IMU , RGB , and RGB-D sensors A simulation class ( RobotDARTSimu ) that handles multiple robots and sensors, and allows for step-by-step simulation A growing list of supported robots along with edited and optimized models to be used with RobotDART (see the robots page for details and examples): PAL Talos humanoid Franka Emika Panda KUKA LBR Iiwa (14kg version) IIT iCub humanoid (without hands) Unitree A1 quadruped robot Dynamixel-based 6-legged robot A simple arm for educational purposes and you can use any URDF A custom graphical interface built on top of Magnum that allows generic customization Support for windowless OpenGL context creation (even in parallel threads!) to allow for camera sensor usage even in parallel jobs running on clusters Support for video recording in simulation time (i.e., not affected by delays of simulator and/or graphics) for visualization or debugging purposes Full-featured Python bindings for fast prototyping RobotDART runs on any Linux distribution and Mac OS","title":"Main Features"},{"location":"#what-robotdart-is-not","text":"RobotDART is primarily intended to be non-interactive (run a simulation, record/view the result), Interaction is limited to changing the view and your own code. No GUI for adding objects or interactively build an environment, RobotDART is not optimized for wheeled robots, RobotDART is not optimized for simulating complex (e.g., mountain-like) terrains.","title":"What RobotDART is not"},{"location":"faq/","text":".md-typeset h1, .md-content__button { display: none; } Frequently Asked Questions \u00b6 This pages provides a user guide of the library through Frequently Asked Questions (FAQ). What is a minimal working example of RobotDART? \u00b6 You can find a minimal working example at hello_world.cpp . This example is creating a world where a hexapod robot is placed just above a floor and left to fall. The robot has no actuation, and there is the simplest graphics configuration. Let's split it down. We first include the appropriate files: C++ Python #include <robot_dart/robot_dart_simu.hpp> #ifdef GRAPHIC #include <robot_dart/gui/magnum/graphics.hpp> #endif import RobotDART as rd We then load our hexapod robot: C++ Python auto robot = std :: make_shared < robot_dart :: Robot > ( \"pexod.urdf\" ); robot = rd . Robot ( \"pexod.urdf\" ); We need to place it above the floor to avoid collision (we can use RobotDART's helpers ;)): C++ Python robot -> set_base_pose ( robot_dart :: make_tf ({ 0. , 0. , 0.2 })); robot . set_base_pose ([ 0. , 0. , 0. , 0. , 0. , 0.2 ]) We can now create the simulation object and add the robot and the floor: C++ Python robot_dart :: RobotDARTSimu simu ( 0.001 ); // dt=0.001, 1KHz simulation simu . add_floor (); simu . add_robot ( robot ); simu = rd . RobotDARTSimu ( 0.001 ); # dt=0.001, 1KHz simulation simu . add_floor (); simu . add_robot ( robot ); If needed or wanted, we can add a graphics component to visualize the scene: C++ Python auto graphics = std :: make_shared < robot_dart :: gui :: magnum :: Graphics > (); simu . set_graphics ( graphics ); graphics -> look_at ({ 0.5 , 3. , 0.75 }, { 0.5 , 0. , 0.2 }); graphics = rd . gui . Graphics () simu . set_graphics ( graphics ) graphics . look_at ([ 0.5 , 3. , 0.75 ], [ 0.5 , 0. , 0.2 ]) Once everything is configured, we can run our simulation for a few seconds: C++ Python simu . run ( 10. ); simu . run ( 10. ) Here's how it looks: What robots are supported in RobotDART? \u00b6 RobotDART supports any robot that can be described by a URDF, SDF, SKEL or MJCF file. Nevertheless, we have a curated list of robots with edited and optimized models to be used with RobotDART (see the robots page for details and examples). How can I load my own URDF/SDF/SKEL/MJCF file? \u00b6 See the robots page for details. How do I enable graphics in my code? \u00b6 To enable graphics in your code, you need to do the following: Install Magnum . See the installation page for details. Create and set a graphics object in the simulation object. Here's an example: C++ Python auto graphics = std :: make_shared < robot_dart :: gui :: magnum :: Graphics > (); simu . set_graphics ( graphics ); graphics -> look_at ({ 0.5 , 3. , 0.75 }, { 0.5 , 0. , 0.2 }); graphics = rd . gui . Graphics () simu . set_graphics ( graphics ) graphics . look_at ([ 0.5 , 3. , 0.75 ], [ 0.5 , 0. , 0.2 ]) I want to have multiple camera sensors. Is it possible? \u00b6 Having multiple camera sensors is indeed possible. We can add as many cameras as we wish along the main camera defined in How do I record a video : C++ Python // Add camera auto camera = std :: make_shared < robot_dart :: sensor :: Camera > ( graphics -> magnum_app (), 256 , 256 ); # Add camera camera = rd . sensor . Camera ( graphics . magnum_app (), 32 , 32 ) How do I record a video? \u00b6 In order to record a video of what the main or any other camera \"sees\", you need to call the function record_video(path) of the graphics class: C++ Python graphics -> record_video ( \"talos_dancing.mp4\" ); graphics . record_video ( \"talos_dancing.mp4\" ) Or the camera class: C++ Python // cameras can also record video camera -> record_video ( \"video-camera.mp4\" ); # cameras can also record video camera . record_video ( \"video-camera.mp4\" ) How can I position a camera to the environment? \u00b6 In order to position a camera inside the world, we need to use the lookAt method of the camera/graphics object: C++ Python // set the position of the camera, and the position where the main camera is looking at Eigen :: Vector3d cam_pos = { -0.5 , -3. , 0.75 }; Eigen :: Vector3d cam_looks_at = { 0.5 , 0. , 0.2 }; camera -> look_at ( cam_pos , cam_looks_at ); # set the position of the camera, and the position where the main camera is looking at cam_pos = [ - 0.5 , - 3. , 0.75 ] cam_looks_at = [ 0.5 , 0. , 0.2 ] camera . look_at ( cam_pos , cam_looks_at ) How can I attach a camera to a moving link? \u00b6 Cameras can be easily attached to a moving link: C++ Python Eigen :: Isometry3d tf ; tf = Eigen :: AngleAxisd ( 3.14 , Eigen :: Vector3d { 1. , 0. , 0. }); tf *= Eigen :: AngleAxisd ( 1.57 , Eigen :: Vector3d { 0. , 0. , 1. }); tf . translation () = Eigen :: Vector3d ( 0. , 0. , 0.1 ); camera -> attach_to_body ( robot -> body_node ( \"iiwa_link_ee\" ), tf ); // cameras are looking towards -z by default tf = dartpy . math . Isometry3 () rot = dartpy . math . AngleAxis ( 3.14 , [ 1. , 0. , 0. ]) rot = rot . multiply ( dartpy . math . AngleAxis ( 1.57 , [ 0. , 0. , 1. ])) . to_rotation_matrix () tf . set_translation ([ 0. , 0. , 0.1 ]) camera . attach_to_body ( robot . body_node ( \"iiwa_link_ee\" ), tf ) # cameras are looking towards -z by default How can I manipulate the camera object? \u00b6 Every camera has its own parameters, i.e a Near plane, a far plane, a Field Of View (FOV), a width and a height (that define the aspect ratio), you can manipulate each one separately: C++ Python camera -> camera (). set_far_plane ( 5.f ); camera -> camera (). set_near_plane ( 0.01f ); camera -> camera (). set_fov ( 60.0f ); camera . camera () . set_far_plane ( 5. ) camera . camera () . set_near_plane ( 0.01 ) camera . camera () . set_fov ( 60.0 ) or all at once: C++ Python camera -> camera (). set_camera_params ( 5. , // far plane 0.01f , // near plane 60.0f , // field of view 600 , // width 400 // height ); camera . camera () . set_camera_params ( 5. , #far plane 0.01 , #near plane 60.0 , # field of view 600 , # width 400 ) #height You can find a complete example at cameras.cpp . How can I interact with the camera? \u00b6 We can move translate the cameras with the WASD keys, zoom in and out using the mouse wheel and rotate the camera with holding the left mouse key and moving the mouse. What do the numbers in the status bar mean? \u00b6 The status bar looks like this: Where simulation time gives us the total simulated time (in seconds), wall time gives us the total time (in seconds) that has passed in real-time once we have started simulating. The next number X.Xx gives us the real-time factor: for example, 1.1x means that the simulation runs 1.1 times faster than real-time, whereas 0.7x means that the simulation runs slower than real-time. The value it: XX ms reports the time it took the last iteration (in milliseconds). The last part gives us whether the simulation tries to adhere to real-time or not. sync means that RobotDART will slow down the simulation in order for it to be in real-time, whereas no-sync means that RobotDART will try to run the simulation as fast as possible. How can I alter the graphics scene (e.g., change lighting conditions)? \u00b6 When creating a graphics object, you can pass a GraphicsConfiguration object that changes the default values: C++ Python robot_dart :: gui :: magnum :: GraphicsConfiguration configuration ; // We can change the width/height of the window (or camera image dimensions) configuration . width = 1280 ; configuration . height = 960 ; configuration . title = \"Graphics Tutorial\" ; // We can set a title for our window // We can change the configuration for shadows configuration . shadowed = true ; configuration . transparent_shadows = true ; configuration . shadow_map_size = 1024 ; // We can also alter some specifications for the lighting configuration . max_lights = 3 ; // maximum number of lights for our scene [default=3] configuration . specular_strength = 0.25 ; // strength of the specular component // Some extra configuration for the main camera configuration . draw_main_camera = true ; configuration . draw_debug = true ; configuration . draw_text = true ; // We can also change the background color [default=black] configuration . bg_color = Eigen :: Vector4d { 1.0 , 1.0 , 1.0 , 1.0 }; // Create the graphics object with the configuration as parameter auto graphics = std :: make_shared < robot_dart :: gui :: magnum :: Graphics > ( configuration ); configuration = rd . gui . GraphicsConfiguration () # We can change the width/height of the window (or camera, dimensions) configuration . width = 1280 configuration . height = 960 configuration . title = \"Graphics Tutorial\" # We can set a title for our window # We can change the configuration for shadows configuration . shadowed = True configuration . transparent_shadows = True configuration . shadow_map_size = 1024 # We can also alter some specifications for the lighting configuration . max_lights = 3 # maximum number of lights for our scene configuration . specular_strength = 0.25 # strength og the specular component # Some extra configuration for the main camera configuration . draw_main_camera = True configuration . draw_debug = True configuration . draw_text = True # We can also change the background color [default = black] configuration . bg_color = [ 1. , 1. , 1. , 1. ] # create the graphics object with the configuration as a parameter graphics = rd . gui . Graphics ( configuration ) You can disable or enable shadows on the fly as well: C++ Python // Disable shadows graphics -> enable_shadows ( false , false ); simu . run ( 1. ); // Enable shadows only for non-transparent objects graphics -> enable_shadows ( true , false ); simu . run ( 1. ); // Enable shadows for transparent objects as well graphics -> enable_shadows ( true , true ); simu . run ( 1. ); # Disable shadows graphics . enable_shadows ( False , False ) simu . run ( 1. ) # Enable shadows only for non-transparent objects graphics . enable_shadows ( True , False ) simu . run ( 1. ) # Enable shadows for transparent objects as well graphics . enable_shadows ( True , True ) simu . run ( 1. ) You can also add your own lights. The application by default creates 2 light sources and the maximum number of lights is 3 (you can change this once before the creation of the graphics object via the GraphicsConfiguration object). So usually before you add your lights, you have to clear the default lights: C++ Python // Clear Lights graphics -> clear_lights (); # Clear Lights graphics . clear_lights () Then you must create a custom light material: C++ Python // Create Light material Magnum :: Float shininess = 1000.f ; Magnum :: Color4 white = { 1.f , 1.f , 1.f , 1.f }; // ambient, diffuse, specular auto custom_material = robot_dart :: gui :: magnum :: gs :: Material ( white , white , white , shininess ); # Clear Light material shininess = 1000. white = magnum . Color4 ( 1. , 1. , 1. , 1. ) # ambient, diffuse, specular custom_material = rd . gui . Material ( white , white , white , shininess ) Now you can add on ore more of the following lights: Point Light : C++ Python // Create point light Magnum :: Vector3 position = { 0.f , 0.f , 2.f }; Magnum :: Float intensity = 1.f ; Magnum :: Vector3 attenuation_terms = { 1.f , 0.f , 0.f }; auto point_light = robot_dart :: gui :: magnum :: gs :: create_point_light ( position , custom_material , intensity , attenuation_terms ); graphics -> add_light ( point_light ); # Create point light position = magnum . Vector3 ( 0. , 0. , 2. ) intensity = 1. attenuation_terms = magnum . Vector3 ( 1. , 0. , 0. ) point_light = rd . gui . create_point_light ( position , custom_material , intensity , attenuation_terms ) graphics . add_light ( point_light ) Spot Light : C++ Python // Create spot light Magnum :: Vector3 position = { 0.f , 0.f , 1.f }; Magnum :: Vector3 direction = { -1.f , -1.f , -1.f }; Magnum :: Float intensity = 1.f ; Magnum :: Vector3 attenuation_terms = { 1.f , 0.f , 0.f }; Magnum :: Float spot_exponent = M_PI ; Magnum :: Float spot_cut_off = M_PI / 8 ; auto spot_light = robot_dart :: gui :: magnum :: gs :: create_spot_light ( position , custom_material , direction , spot_exponent , spot_cut_off , intensity , attenuation_terms ); graphics -> add_light ( spot_light ); # Create spot light position = magnum . Vector3 ( 0. , 0. , 1. ) direction = magnum . Vector3 ( - 1 , - 1 , - 1 ) intensity = 1. attenuation_terms = magnum . Vector3 ( 1. , 0. , 0. ) spot_exponent = np . pi spot_cut_off = np . pi / 8 spot_light = rd . gui . create_spot_light ( position , custom_material , direction , spot_exponent , spot_cut_off , intensity , attenuation_terms ) graphics . add_light ( spot_light ) Directional Light : C++ Python // Create directional light Magnum :: Vector3 direction = { -1.f , -1.f , -1.f }; auto directional_light = robot_dart :: gui :: magnum :: gs :: create_directional_light ( direction , custom_material ); graphics -> add_light ( directional_light ); # Create directional light direction = magnum . Vector3 ( - 1 , - 1 , - 1 ) directional_light = rd . gui . create_directional_light ( direction , custom_material ) graphics . add_light ( directional_light ) I want to visualize a target configuration of my robot, is this possible? \u00b6 Yes this is possible. RobotDART gives the ability to create a clone of your robot that has no physics, no contacts, just visuals: C++ Python // Add a ghost robot; only visuals, no dynamics, no collision auto ghost = robot -> clone_ghost (); simu . add_robot ( ghost ); # Add a ghost robot; only visuals, no dynamics, no collision ghost = robot . clone_ghost () simu . add_robot ( ghost ) How can I control my robot ? \u00b6 PD control C++ Python // add a PD-controller to the arm // set desired positions Eigen :: VectorXd ctrl = robot_dart :: make_vector ({ 0. , M_PI / 4. , 0. , - M_PI / 4. , 0. , M_PI / 2. , 0. , 0. }); // add the controller to the robot auto controller = std :: make_shared < robot_dart :: control :: PDControl > ( ctrl ); robot -> add_controller ( controller ); controller -> set_pd ( 300. , 50. ); # add a PD-controller to the arm # set desired positions ctrl = [ 0. , np . pi / 4. , 0. , - np . pi / 4. , 0. , np . pi / 2. , 0. , 0. ] # add the controller to the robot controller = rd . PDControl ( ctrl ) robot . add_controller ( controller ) controller . set_pd ( 300. , 50. ) Simple control C++ Python auto controller1 = std :: make_shared < robot_dart :: control :: SimpleControl > ( ctrl ); robot -> add_controller ( controller1 ); controller1 = rd . SimpleControl ( ctrl ) robot . add_controller ( controller1 ) Robot control C++ Python class MyController : public robot_dart :: control :: RobotControl { public : MyController () : robot_dart :: control :: RobotControl () {} MyController ( const Eigen :: VectorXd & ctrl , bool full_control ) : robot_dart :: control :: RobotControl ( ctrl , full_control ) {} MyController ( const Eigen :: VectorXd & ctrl , const std :: vector < std :: string >& dof_names ) : robot_dart :: control :: RobotControl ( ctrl , dof_names ) {} void configure () override { _active = true ; } Eigen :: VectorXd calculate ( double ) override { auto robot = _robot . lock (); Eigen :: VectorXd cmd = 100. * ( _ctrl - robot -> positions ( _controllable_dofs )); return cmd ; } std :: shared_ptr < robot_dart :: control :: RobotControl > clone () const override { return std :: make_shared < MyController > ( * this ); } }; class MyController ( rd . RobotControl ): def __init__ ( self , ctrl , full_control ): rd . RobotControl . __init__ ( self , ctrl , full_control ) def __init__ ( self , ctrl , controllable_dofs ): rd . RobotControl . __init__ ( self , ctrl , controllable_dofs ) def configure ( self ): self . _active = True def calculate ( self , t ): target = np . array ([ self . _ctrl ]) cmd = 100 * ( target - self . robot () . positions ( self . _controllable_dofs )) return cmd [ 0 ] # TO-DO: This is NOT working at the moment! def clone ( self ): return MyController ( self . _ctrl , self . _controllable_dofs ) Is there a way to control the simulation timestep? \u00b6 When creating a RobotDARTSimu object you choose the simulation timestep: C++ Python // choose time step of 0.001 seconds robot_dart :: RobotDARTSimu simu ( 0.001 ); # choose time step of 0.001 seconds simu = rd . RobotDARTSimu ( 0.001 ) which can later be modified by: C++ Python // set timestep to 0.005 and update control frequency(bool) simu . set_timestep ( 0.005 , true ); # set timestep to 0.005 and update control frequency(bool) simu . set_timestep ( 0.005 , True ) I want to simulate a mars environment, is it possible to change the gravitational force of the simulation environment? \u00b6 Yes you can modify the gravitational forces 3-dimensional vector of the simulation: C++ Python // Set gravitational force of mars Eigen :: Vector3d mars_gravity = { 0. , 0. , -3.721 }; simu . set_gravity ( mars_gravity ); # set gravitational force of mars mars_gravity = [ 0. , 0. , - 3.721 ] simu . set_gravity ( mars_gravity ) Which collision detectors are available? What are their differences? How can I choose between them? \u00b6 DART FCL ODE Bullet Support only basic shapes Full-featured collision detector fully integrated by DART External collision detector of ODE External collision detector of Bullet This is building along with DART This is a required dependency of DART Needs an external library Needs an external library Very fast for small scenes Accurate detailed collisions, but not very fast Fast collision detection (the integration is not complete) Fast and accurate collision detection (works well for wheels as well) We can easily select one of the available collision detectors using the simulator object: C++ Python simu . set_collision_detector ( \"fcl\" ); // collision_detector can be \"dart\", \"fcl\", \"ode\" or \"bullet\" (case does not matter) simu . set_collision_detector ( \"fcl\" ) # collision_detector can be \"dart\", \"fcl\", \"ode\" or \"bullet\" (case does not matter) My robot does not self-collide. How can I change this? \u00b6 One possible cause may be the fact that self collision is disabled, you can check and change this: C++ Python if ( ! robot -> self_colliding ()) { std :: cout << \"Self collision is not enabled\" << std :: endl ; // set self collisions to true and adjacent collisions to false robot -> set_self_collision ( true , false ); } if ( not robot . self_colliding ()): print ( \"Self collision is not enabled\" ) # set self collisions to true and adjacent collisions to false robot . set_self_collision ( True , False ) How can I compute kinematic/dynamic properties of my robot (e.g., Jacobians, Mass Matrix)? \u00b6 Kinematic Properties: C++ Python // Get Joint Positions(Angles) auto joint_positions = robot -> positions (); // Get Joint Velocities auto joint_vels = robot -> velocities (); // Get Joint Accelerations auto joint_accs = robot -> accelerations (); // Get link_name(str) Transformation matrix with respect to the world frame. auto eef_tf = robot -> body_pose ( link_name ); // Get translation vector from transformation matrix auto eef_pos = eef_tf . translation (); // Get rotation matrix from tranformation matrix auto eef_rot = eef_tf . rotation (); // Get link_name 6d pose vector [logmap(eef_tf.linear()), eef_tf.translation()] auto eef_pose_vec = robot -> body_pose_vec ( link_name ); // Get link_name 6d velocity vector [angular, cartesian] auto eef_vel = robot -> body_velocity ( link_name ); // Get link_name 6d acceleration vector [angular, cartesian] auto eef_acc = robot -> body_acceleration ( link_name ); // Jacobian targeting the origin of link_name(str) auto jacobian = robot -> jacobian ( link_name ); // Jacobian time derivative auto jacobian_deriv = robot -> jacobian_deriv ( link_name ); // Center of Mass Jacobian auto com_jacobian = robot -> com_jacobian (); // Center of Mass Jacobian Time Derivative auto com_jacobian_deriv = robot -> com_jacobian_deriv (); # Get Joint Positions(Angles) joint_positions = robot . positions () # Get Joint Velocities joint_vels = robot . velocities () # Get Joint Accelerations joint_accs = robot . accelerations () # Get link_name(str) Transformation matrix with respect to the world frame. eef_tf = robot . body_pose ( link_name ) # Get translation vector from transformation matrix eef_pos = eef_tf . translation () # Get rotation matrix from tranformation matrix eef_rot = eef_tf . rotation () # Get link_name 6d pose vector [logmap(eef_tf.linear()), eef_tf.translation()] eef_pose_vec = robot . body_pose_vec ( link_name ) # Get link_name 6d velocity vector [angular, cartesian] eef_vel = robot . body_velocity ( link_name ) # Get link_name 6d acceleration vector [angular, cartesian] eef_acc = robot . body_acceleration ( link_name ) # Jacobian targeting the origin of link_name(str) jacobian = robot . jacobian ( link_name ) # Jacobian time derivative jacobian_deriv = robot . jacobian_deriv ( link_name ) # Center of Mass Jacobian com_jacobian = robot . com_jacobian () # Center of Mass Jacobian Time Derivative com_jacobian_deriv = robot . com_jacobian_deriv () Dynamic Properties: C++ Python // Get Joint Forces auto joint_forces = robot -> forces (); // Get link's mass auto eef_mass = robot -> body_mass ( link_name ); // Mass Matrix of robot auto mass_matrix = robot -> mass_matrix (); // Inverse of Mass Matrix auto inv_mass_matrix = robot -> inv_mass_matrix (); // Augmented Mass matrix auto aug_mass_matrix = robot -> aug_mass_matrix (); // Inverse of Augmented Mass matrix auto inv_aug_mass_matrix = robot -> inv_aug_mass_matrix (); // Coriolis Force vector auto coriolis = robot -> coriolis_forces (); // Gravity Force vector auto gravity = robot -> gravity_forces (); // Combined vector of Coriolis Force and Gravity Force auto coriolis_gravity = robot -> coriolis_gravity_forces (); // Constraint Force Vector auto constraint_forces = robot -> constraint_forces (); # Get Joint Forces joint_forces = robot . forces () # Get link's mass eef_mass = robot . body_mass ( link_name ) # Mass Matrix of robot mass_matrix = robot . mass_matrix () # Inverse of Mass Matrix inv_mass_matrix = robot . inv_mass_matrix () # Augmented Mass matrix aug_mass_matrix = robot . aug_mass_matrix () # Inverse of Augmented Mass matrix inv_aug_mass_matrix = robot . inv_aug_mass_matrix () # Coriolis Force vector coriolis = robot . coriolis_forces () # Gravity Force vector gravity = robot . gravity_forces () # Combined vector of Coriolis Force and Gravity Force coriolis_gravity = robot . coriolis_gravity_forces () # NOT IMPLEMENTED # # Constraint Force Vector # constraint_forces = robot.constraint_forces() Is there a way to change the joint or link (body) properties (e.g., actuation, mass)? \u00b6 There are 6 types of actuators available, you can set the same actuator to multiple joints at once, or you can set each sensor separately: C++ Python // Set all DoFs to same actuator robot -> set_actuator_types ( \"servo\" ); // actuator types can be \"servo\", \"torque\", \"velocity\", \"passive\", \"locked\", \"mimic\" // You can also set actuator types separately robot -> set_actuator_type ( \"torque\" , \"iiwa_joint_5\" ); # Set all DoFs to same actuator # actuator types can be \"servo\", \"torque\", \"velocity\", \"passive\", \"locked\", \"mimic\" robot . set_actuator_types ( \"servo\" ) # You can also set actuator types separately robot . set_actuator_type ( \"torque\" , \"iiwa_joint_5\" ) To enable position and velocity limits for the actuators: C++ Python // \u0395nforce joint position and velocity limits robot -> set_position_enforced ( true ); # \u0395nforce joint position and velocity limits robot . set_position_enforced ( True ) Every DOF's limits (position, velocity, acceleration, force) can be modified: C++ Python // Modify Position Limits Eigen :: VectorXd pos_upper_lims ( 7 ); pos_upper_lims << 2.096 , 2.096 , 2.096 , 2.096 , 2.096 , 2.096 , 2.096 ; robot -> set_position_upper_limits ( pos_upper_lims , dof_names ); robot -> set_position_lower_limits ( - pos_upper_lims , dof_names ); // Modify Velocity Limits Eigen :: VectorXd vel_upper_lims ( 7 ); vel_upper_lims << 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 ; robot -> set_velocity_upper_limits ( vel_upper_lims , dof_names ); robot -> set_velocity_lower_limits ( - vel_upper_lims , dof_names ); // Modify Force Limits Eigen :: VectorXd force_upper_lims ( 7 ); force_upper_lims << 150 , 150 , 150 , 150 , 150 , 150 , 150 ; robot -> set_force_upper_limits ( force_upper_lims , dof_names ); robot -> set_force_lower_limits ( - force_upper_lims , dof_names ); // Modify Acceleration Limits Eigen :: VectorXd acc_upper_lims ( 7 ); acc_upper_lims << 1500 , 1500 , 1500 , 1500 , 1500 , 1500 , 1500 ; robot -> set_acceleration_upper_limits ( acc_upper_lims , dof_names ); robot -> set_acceleration_lower_limits ( - acc_upper_lims , dof_names ); # Modify Position Limits pos_upper_lims = np . array ([ 2.096 , 2.096 , 2.096 , 2.096 , 2.096 , 2.096 , 2.096 ]) robot . set_position_upper_limits ( pos_upper_lims , dof_names ) robot . set_position_lower_limits ( - 1 * pos_upper_lims , dof_names ) # Modify Velocity Limits vel_upper_lims = np . array ([ 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 ]) robot . set_velocity_upper_limits ( vel_upper_lims , dof_names ) robot . set_velocity_lower_limits ( - 1 * vel_upper_lims , dof_names ) # Modify Force Limits force_upper_lims = np . array ([ 150 , 150 , 150 , 150 , 150 , 150 , 150 ]) robot . set_force_upper_limits ( force_upper_lims , dof_names ) robot . set_force_lower_limits ( - 1 * force_upper_lims , dof_names ) # Modify Acceleration Limits acc_upper_lims = np . array ([ 1500 , 1500 , 1500 , 1500 , 1500 , 1500 , 1500 ]) robot . set_acceleration_upper_limits ( acc_upper_lims , dof_names ) robot . set_acceleration_lower_limits ( - 1 * acc_upper_lims , dof_names ) You can also modify the damping coefficients, coulomb frictions and spring stiffness of every DOF: C++ Python // Modify Damping Coefficients std :: vector < double > damps = { 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 }; robot -> set_damping_coeffs ( damps , dof_names ); // Modify Coulomb Frictions std :: vector < double > cfrictions = { 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 }; robot -> set_coulomb_coeffs ( cfrictions , dof_names ); // Modify Spring Stiffness std :: vector < double > stiffnesses = { 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 }; robot -> set_spring_stiffnesses ( stiffnesses , dof_names ); # Modify Damping Coefficients damps = [ 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 ] robot . set_damping_coeffs ( damps , dof_names ) # Modify Coulomb Frictions cfrictions = [ 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 ] robot . set_coulomb_coeffs ( cfrictions , dof_names ) # Modify Spring Stiffness stiffnesses = [ 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 ] robot . set_spring_stiffnesses ( stiffnesses , dof_names ) What are the supported sensors? How can I use an IMU? \u00b6 Sensors in RobotDART can be added only through the simulator object. All of the sensors can be added without being attached to any body or joint but some of them can operate only when attached to something (e.g. ForceTorque sensors). Torque sensor \u00b6 Torque sensors can be added to every joint of the robot: // Add torque sensors to the robot int ct = 0 ; std :: vector < std :: shared_ptr < robot_dart :: sensor :: Torque >> tq_sensors ( robot -> num_dofs ()); for ( const auto & joint : robot -> dof_names ()) tq_sensors [ ct ++ ] = simu . add_sensor < robot_dart :: sensor :: Torque > ( robot , joint , 1000 ); Torque sensors measure the torque \\(\\tau \\in \\rm I\\!R^n\\) of the attached joint (where \\(n\\) is the DOFs of the joint): // vector that contains the torque measurement for every joint (scalar) Eigen :: VectorXd torques_measure ( robot -> num_dofs ()); for ( const auto & tq_sens : tq_sensors ) torques_measure . block < 1 , 1 > ( ct ++ , 0 ) = tq_sens -> torques (); Force-Torque sensor \u00b6 Force-Torque sensors can be added to every joint of the robot: // Add force-torque sensors to the robot ct = 0 ; std :: vector < std :: shared_ptr < robot_dart :: sensor :: ForceTorque >> f_tq_sensors ( robot -> num_dofs ()); for ( const auto & joint : robot -> dof_names ()) f_tq_sensors [ ct ++ ] = simu . add_sensor < robot_dart :: sensor :: ForceTorque > ( robot , joint , 1000 , \"parent_to_child\" ); Torque sensors measure the force \\(\\boldsymbol{F} \\in \\rm I\\!R^3\\) , the torque \\(\\boldsymbol{\\tau} \\in \\rm I\\!R^3\\) and the wrench \\(\\boldsymbol{\\mathcal{F}} =\\begin{bmatrix} \\tau, F\\end{bmatrix}\\in \\rm I\\!R^6\\) of the attached joint: // matrix that contains the torque measurement for every joint (3d vector) Eigen :: MatrixXd ft_torques_measure ( robot -> num_dofs (), 3 ); // matrix that contains the force measurement for every joint (3d vector) Eigen :: MatrixXd ft_forces_measure ( robot -> num_dofs (), 3 ); // matrix that contains the wrench measurement for every joint (6d vector)[torque, force] Eigen :: MatrixXd ft_wrench_measure ( robot -> num_dofs (), 6 ); ct = 0 ; for ( const auto & f_tq_sens : f_tq_sensors ) { ft_torques_measure . block < 1 , 3 > ( ct , 0 ) = f_tq_sens -> torque (); ft_forces_measure . block < 1 , 3 > ( ct , 0 ) = f_tq_sens -> force (); ft_wrench_measure . block < 1 , 6 > ( ct , 0 ) = f_tq_sens -> wrench (); ct ++ ; } IMU sensor \u00b6 IMU sensors can be added to every link of the robot: // Add IMU sensors to the robot ct = 0 ; std :: vector < std :: shared_ptr < robot_dart :: sensor :: IMU >> imu_sensors ( robot -> num_bodies ()); for ( const auto & body_node : robot -> body_names ()) { // _imu(std::make_shared<sensor::IMU>(sensor::IMUConfig(body_node(\"head\"), frequency))), imu_sensors [ ct ++ ] = simu . add_sensor < robot_dart :: sensor :: IMU > ( robot_dart :: sensor :: IMUConfig ( robot -> body_node ( body_node ), 1000 )); } IMU sensors measure the angular position vector \\(\\boldsymbol{\\theta} \\in \\rm I\\!R^3\\) , the angular velocity \\(\\boldsymbol{\\omega} \\in \\rm I\\!R^3\\) and the linear acceleration \\(\\boldsymbol{\\alpha} \\in \\rm I\\!R^3\\) of the attached link: Eigen :: MatrixXd imu_angular_positions_measure ( robot -> num_bodies (), 3 ); Eigen :: MatrixXd imu_angular_velocities_measure ( robot -> num_bodies (), 3 ); Eigen :: MatrixXd imu_linear_acceleration_measure ( robot -> num_bodies (), 3 ); ct = 0 ; for ( const auto & imu_sens : imu_sensors ) { imu_angular_positions_measure . block < 1 , 3 > ( ct , 0 ) = imu_sens -> angular_position_vec (); imu_angular_velocities_measure . block < 1 , 3 > ( ct , 0 ) = imu_sens -> angular_velocity (); imu_linear_acceleration_measure . block < 1 , 3 > ( ct , 0 ) = imu_sens -> linear_acceleration (); ct ++ ; } RGB sensor \u00b6 Any camera can be used as an RGB sensor: // a nested std::vector (w*h*3) of the last image taken can be retrieved auto rgb_image = camera -> image (); We can easily save the image and/or transform it to grayscale: // we can also save them to png robot_dart :: gui :: save_png_image ( \"camera-small.png\" , rgb_image ); // convert an rgb image to grayscale (useful in some cases) auto gray_image = robot_dart :: gui :: convert_rgb_to_grayscale ( rgb_image ); robot_dart :: gui :: save_png_image ( \"camera-gray.png\" , gray_image ); RGB_D sensor \u00b6 Any camera can also be configured to also record depth: camera -> camera (). record ( true , true ); // cameras are recording color images by default, enable depth images as well for this example We can then read the RGB and depth images: // get the depth image from a camera // with a version for visualization or bigger differences in the output auto rgb_d_image = camera -> depth_image (); // and the raw values that can be used along with the camera parameters to transform the image to point-cloud auto rgb_d_image_raw = camera -> raw_depth_image (); We can save the depth images as well: robot_dart :: gui :: save_png_image ( \"camera-depth.png\" , rgb_d_image ); robot_dart :: gui :: save_png_image ( \"camera-depth-raw.png\" , rgb_d_image_raw ); How can I measure forces being applied to my robot? \u00b6 How can I spawn multiple robots in parallel? \u00b6 The best way to do so is to create a Robot pool. With a robot pool you: Minimize the overhead of loading robots (it happens only once!) or cloning robots (it never happens) Make sure that your robots are \"clean\" once released from each thread Focus on the important stuff rather than handling robots and threads Let's see a more practical example: First we need to include the proper header: #include <robot_dart/robot_pool.hpp> Then we create a creator function and the pool object: namespace pool { // This function should load one robot: here we load Talos inline std :: shared_ptr < robot_dart :: Robot > robot_creator () { return std :: make_shared < robot_dart :: robots :: Talos > (); } // To create the object we need to pass the robot_creator function and the number of maximum parallel threads robot_dart :: RobotPool robot_pool ( robot_creator , NUM_THREADS ); } // namespace pool The creator function is the function responsible for loading your robot. This should basically look like a standalone code to load or create a robot. Next, we create a few threads that utilize the robots (in your code you might be using OpenMP or TBB): // for the example, we run NUM_THREADS threads of eval_robot() std :: vector < std :: thread > threads ( NUM_THREADS * 2 ); // *2 to see some reuse for ( size_t i = 0 ; i < threads . size (); ++ i ) threads [ i ] = std :: thread ( eval_robot , i ); // eval_robot is the function that uses the robot An example evaluation function: inline void eval_robot ( int i ) { // We get one available robot auto robot = pool :: robot_pool . get_robot (); std :: cout << \"Robot \" << i << \" got [\" << robot -> skeleton () << \"]\" << std :: endl ; /// --- some robot_dart code --- simulate_robot ( robot ); // --- do something with the result std :: cout << \"End of simulation \" << i << std :: endl ; // CRITICAL : free your robot ! pool :: robot_pool . free_robot ( robot ); std :: cout << \"Robot \" << i << \" freed!\" << std :: endl ; } I need to simulate many worlds with camera sensors in parallel. How can I do this? \u00b6 On magnum_contexts.cpp you can find an example showcasing the use of many worlds with camera sensors in parallel. The main takeaway is that we need to pre-allocate OpenGL contexts so that each thread can take one and use it to render their worlds. // Load robot from URDF auto global_robot = std :: make_shared < robot_dart :: robots :: Iiwa > (); std :: vector < std :: thread > workers ; // Set maximum number of parallel GL contexts (this is GPU-dependent) robot_dart :: gui :: magnum :: GlobalData :: instance () -> set_max_contexts ( 4 ); // We want 15 parallel simulations with different GL context each size_t N_workers = 15 ; std :: mutex mutex ; size_t id = 0 ; // Launch the workers for ( size_t i = 0 ; i < N_workers ; i ++ ) { workers . push_back ( std :: thread ([ & ] { mutex . lock (); size_t index = id ++ ; mutex . unlock (); // Get the GL context -- this is a blocking call // will wait until one GL context is available // get_gl_context(gl_context); // this call will not sleep between failed queries get_gl_context_with_sleep ( gl_context , 20 ); // this call will sleep 20ms between each failed query // Do the simulation auto robot = global_robot -> clone (); robot_dart :: RobotDARTSimu simu ( 0.001 ); Eigen :: VectorXd ctrl = robot_dart :: make_vector ({ 0. , M_PI / 3. , 0. , - M_PI / 4. , 0. , 0. , 0. }); auto controller = std :: make_shared < robot_dart :: control :: PDControl > ( ctrl ); robot -> add_controller ( controller ); controller -> set_pd ( 300. , 50. ); // Magnum graphics robot_dart :: gui :: magnum :: GraphicsConfiguration configuration = robot_dart :: gui :: magnum :: WindowlessGraphics :: default_configuration (); configuration . width = 1024 ; configuration . height = 768 ; auto graphics = std :: make_shared < robot_dart :: gui :: magnum :: WindowlessGraphics > ( configuration ); simu . set_graphics ( graphics ); // Position the camera differently for each thread to visualize the difference graphics -> look_at ({ 0.4 * index , 3.5 - index * 0.1 , 2. }, { 0. , 0. , 0.25 }); // record images from main camera/graphics // graphics->set_recording(true); // WindowlessGLApplication records images by default simu . add_robot ( robot ); simu . run ( 6 ); // Save the image for verification robot_dart :: gui :: save_png_image ( \"camera_\" + std :: to_string ( index ) + \".png\" , graphics -> image ()); // Release the GL context for another thread to use release_gl_context ( gl_context ); })); } // Wait for all the workers for ( size_t i = 0 ; i < workers . size (); i ++ ) { workers [ i ]. join (); } I do not know how to use waf. How can I detect RobotDART from CMake? \u00b6 You need to use waf to build RobotDART, but when installing the library a CMake module is installed. Thus it is possible use RobotDART in your code using CMake. You can find a complete example at cmake/example . In short the CMake would look like this: cmake_minimum_required ( VERSION 3.10 FATAL_ERROR ) project ( robot_dart_example ) # we ask for Magnum because we want to build the graphics find_package ( RobotDART REQUIRED OPTIONAL_COMPONENTS Magnum ) add_executable ( robot_dart_example example.cpp ) target_link_libraries ( robot_dart_example RobotDART::Simu ) if ( RobotDART_Magnum_FOUND ) add_executable ( robot_dart_example_graphics example.cpp ) target_link_libraries ( robot_dart_example_graphics RobotDART::Simu RobotDART::Magnum ) endif () I prefer coding in python. How can I use RobotDART? \u00b6 RobotDART comes with python bindinds. Please refer to the installation page to see how to install them. Once the python bindings are installed, we can use RobotDART from python! An example is available at example.py . There is mostly an one-to-one mapping between C++ and python objects and functions.","title":"FAQ"},{"location":"faq/#frequently-asked-questions","text":"This pages provides a user guide of the library through Frequently Asked Questions (FAQ).","title":"Frequently Asked Questions"},{"location":"faq/#what-is-a-minimal-working-example-of-robotdart","text":"You can find a minimal working example at hello_world.cpp . This example is creating a world where a hexapod robot is placed just above a floor and left to fall. The robot has no actuation, and there is the simplest graphics configuration. Let's split it down. We first include the appropriate files: C++ Python #include <robot_dart/robot_dart_simu.hpp> #ifdef GRAPHIC #include <robot_dart/gui/magnum/graphics.hpp> #endif import RobotDART as rd We then load our hexapod robot: C++ Python auto robot = std :: make_shared < robot_dart :: Robot > ( \"pexod.urdf\" ); robot = rd . Robot ( \"pexod.urdf\" ); We need to place it above the floor to avoid collision (we can use RobotDART's helpers ;)): C++ Python robot -> set_base_pose ( robot_dart :: make_tf ({ 0. , 0. , 0.2 })); robot . set_base_pose ([ 0. , 0. , 0. , 0. , 0. , 0.2 ]) We can now create the simulation object and add the robot and the floor: C++ Python robot_dart :: RobotDARTSimu simu ( 0.001 ); // dt=0.001, 1KHz simulation simu . add_floor (); simu . add_robot ( robot ); simu = rd . RobotDARTSimu ( 0.001 ); # dt=0.001, 1KHz simulation simu . add_floor (); simu . add_robot ( robot ); If needed or wanted, we can add a graphics component to visualize the scene: C++ Python auto graphics = std :: make_shared < robot_dart :: gui :: magnum :: Graphics > (); simu . set_graphics ( graphics ); graphics -> look_at ({ 0.5 , 3. , 0.75 }, { 0.5 , 0. , 0.2 }); graphics = rd . gui . Graphics () simu . set_graphics ( graphics ) graphics . look_at ([ 0.5 , 3. , 0.75 ], [ 0.5 , 0. , 0.2 ]) Once everything is configured, we can run our simulation for a few seconds: C++ Python simu . run ( 10. ); simu . run ( 10. ) Here's how it looks:","title":"What is a minimal working example of RobotDART?"},{"location":"faq/#what-robots-are-supported-in-robotdart","text":"RobotDART supports any robot that can be described by a URDF, SDF, SKEL or MJCF file. Nevertheless, we have a curated list of robots with edited and optimized models to be used with RobotDART (see the robots page for details and examples).","title":"What robots are supported in RobotDART?"},{"location":"faq/#how-can-i-load-my-own-urdfsdfskelmjcf-file","text":"See the robots page for details.","title":"How can I load my own URDF/SDF/SKEL/MJCF file?"},{"location":"faq/#how-do-i-enable-graphics-in-my-code","text":"To enable graphics in your code, you need to do the following: Install Magnum . See the installation page for details. Create and set a graphics object in the simulation object. Here's an example: C++ Python auto graphics = std :: make_shared < robot_dart :: gui :: magnum :: Graphics > (); simu . set_graphics ( graphics ); graphics -> look_at ({ 0.5 , 3. , 0.75 }, { 0.5 , 0. , 0.2 }); graphics = rd . gui . Graphics () simu . set_graphics ( graphics ) graphics . look_at ([ 0.5 , 3. , 0.75 ], [ 0.5 , 0. , 0.2 ])","title":"How do I enable graphics in my code?"},{"location":"faq/#i-want-to-have-multiple-camera-sensors-is-it-possible","text":"Having multiple camera sensors is indeed possible. We can add as many cameras as we wish along the main camera defined in How do I record a video : C++ Python // Add camera auto camera = std :: make_shared < robot_dart :: sensor :: Camera > ( graphics -> magnum_app (), 256 , 256 ); # Add camera camera = rd . sensor . Camera ( graphics . magnum_app (), 32 , 32 )","title":"I want to have multiple camera sensors. Is it possible?"},{"location":"faq/#how-do-i-record-a-video","text":"In order to record a video of what the main or any other camera \"sees\", you need to call the function record_video(path) of the graphics class: C++ Python graphics -> record_video ( \"talos_dancing.mp4\" ); graphics . record_video ( \"talos_dancing.mp4\" ) Or the camera class: C++ Python // cameras can also record video camera -> record_video ( \"video-camera.mp4\" ); # cameras can also record video camera . record_video ( \"video-camera.mp4\" )","title":"How do I record a video?"},{"location":"faq/#how-can-i-position-a-camera-to-the-environment","text":"In order to position a camera inside the world, we need to use the lookAt method of the camera/graphics object: C++ Python // set the position of the camera, and the position where the main camera is looking at Eigen :: Vector3d cam_pos = { -0.5 , -3. , 0.75 }; Eigen :: Vector3d cam_looks_at = { 0.5 , 0. , 0.2 }; camera -> look_at ( cam_pos , cam_looks_at ); # set the position of the camera, and the position where the main camera is looking at cam_pos = [ - 0.5 , - 3. , 0.75 ] cam_looks_at = [ 0.5 , 0. , 0.2 ] camera . look_at ( cam_pos , cam_looks_at )","title":"How can I position a camera to the environment?"},{"location":"faq/#how-can-i-attach-a-camera-to-a-moving-link","text":"Cameras can be easily attached to a moving link: C++ Python Eigen :: Isometry3d tf ; tf = Eigen :: AngleAxisd ( 3.14 , Eigen :: Vector3d { 1. , 0. , 0. }); tf *= Eigen :: AngleAxisd ( 1.57 , Eigen :: Vector3d { 0. , 0. , 1. }); tf . translation () = Eigen :: Vector3d ( 0. , 0. , 0.1 ); camera -> attach_to_body ( robot -> body_node ( \"iiwa_link_ee\" ), tf ); // cameras are looking towards -z by default tf = dartpy . math . Isometry3 () rot = dartpy . math . AngleAxis ( 3.14 , [ 1. , 0. , 0. ]) rot = rot . multiply ( dartpy . math . AngleAxis ( 1.57 , [ 0. , 0. , 1. ])) . to_rotation_matrix () tf . set_translation ([ 0. , 0. , 0.1 ]) camera . attach_to_body ( robot . body_node ( \"iiwa_link_ee\" ), tf ) # cameras are looking towards -z by default","title":"How can I attach a camera to a moving link?"},{"location":"faq/#how-can-i-manipulate-the-camera-object","text":"Every camera has its own parameters, i.e a Near plane, a far plane, a Field Of View (FOV), a width and a height (that define the aspect ratio), you can manipulate each one separately: C++ Python camera -> camera (). set_far_plane ( 5.f ); camera -> camera (). set_near_plane ( 0.01f ); camera -> camera (). set_fov ( 60.0f ); camera . camera () . set_far_plane ( 5. ) camera . camera () . set_near_plane ( 0.01 ) camera . camera () . set_fov ( 60.0 ) or all at once: C++ Python camera -> camera (). set_camera_params ( 5. , // far plane 0.01f , // near plane 60.0f , // field of view 600 , // width 400 // height ); camera . camera () . set_camera_params ( 5. , #far plane 0.01 , #near plane 60.0 , # field of view 600 , # width 400 ) #height You can find a complete example at cameras.cpp .","title":"How can I manipulate the camera object?"},{"location":"faq/#how-can-i-interact-with-the-camera","text":"We can move translate the cameras with the WASD keys, zoom in and out using the mouse wheel and rotate the camera with holding the left mouse key and moving the mouse.","title":"How can I interact with the camera?"},{"location":"faq/#what-do-the-numbers-in-the-status-bar-mean","text":"The status bar looks like this: Where simulation time gives us the total simulated time (in seconds), wall time gives us the total time (in seconds) that has passed in real-time once we have started simulating. The next number X.Xx gives us the real-time factor: for example, 1.1x means that the simulation runs 1.1 times faster than real-time, whereas 0.7x means that the simulation runs slower than real-time. The value it: XX ms reports the time it took the last iteration (in milliseconds). The last part gives us whether the simulation tries to adhere to real-time or not. sync means that RobotDART will slow down the simulation in order for it to be in real-time, whereas no-sync means that RobotDART will try to run the simulation as fast as possible.","title":"What do the numbers in the status bar mean?"},{"location":"faq/#how-can-i-alter-the-graphics-scene-eg-change-lighting-conditions","text":"When creating a graphics object, you can pass a GraphicsConfiguration object that changes the default values: C++ Python robot_dart :: gui :: magnum :: GraphicsConfiguration configuration ; // We can change the width/height of the window (or camera image dimensions) configuration . width = 1280 ; configuration . height = 960 ; configuration . title = \"Graphics Tutorial\" ; // We can set a title for our window // We can change the configuration for shadows configuration . shadowed = true ; configuration . transparent_shadows = true ; configuration . shadow_map_size = 1024 ; // We can also alter some specifications for the lighting configuration . max_lights = 3 ; // maximum number of lights for our scene [default=3] configuration . specular_strength = 0.25 ; // strength of the specular component // Some extra configuration for the main camera configuration . draw_main_camera = true ; configuration . draw_debug = true ; configuration . draw_text = true ; // We can also change the background color [default=black] configuration . bg_color = Eigen :: Vector4d { 1.0 , 1.0 , 1.0 , 1.0 }; // Create the graphics object with the configuration as parameter auto graphics = std :: make_shared < robot_dart :: gui :: magnum :: Graphics > ( configuration ); configuration = rd . gui . GraphicsConfiguration () # We can change the width/height of the window (or camera, dimensions) configuration . width = 1280 configuration . height = 960 configuration . title = \"Graphics Tutorial\" # We can set a title for our window # We can change the configuration for shadows configuration . shadowed = True configuration . transparent_shadows = True configuration . shadow_map_size = 1024 # We can also alter some specifications for the lighting configuration . max_lights = 3 # maximum number of lights for our scene configuration . specular_strength = 0.25 # strength og the specular component # Some extra configuration for the main camera configuration . draw_main_camera = True configuration . draw_debug = True configuration . draw_text = True # We can also change the background color [default = black] configuration . bg_color = [ 1. , 1. , 1. , 1. ] # create the graphics object with the configuration as a parameter graphics = rd . gui . Graphics ( configuration ) You can disable or enable shadows on the fly as well: C++ Python // Disable shadows graphics -> enable_shadows ( false , false ); simu . run ( 1. ); // Enable shadows only for non-transparent objects graphics -> enable_shadows ( true , false ); simu . run ( 1. ); // Enable shadows for transparent objects as well graphics -> enable_shadows ( true , true ); simu . run ( 1. ); # Disable shadows graphics . enable_shadows ( False , False ) simu . run ( 1. ) # Enable shadows only for non-transparent objects graphics . enable_shadows ( True , False ) simu . run ( 1. ) # Enable shadows for transparent objects as well graphics . enable_shadows ( True , True ) simu . run ( 1. ) You can also add your own lights. The application by default creates 2 light sources and the maximum number of lights is 3 (you can change this once before the creation of the graphics object via the GraphicsConfiguration object). So usually before you add your lights, you have to clear the default lights: C++ Python // Clear Lights graphics -> clear_lights (); # Clear Lights graphics . clear_lights () Then you must create a custom light material: C++ Python // Create Light material Magnum :: Float shininess = 1000.f ; Magnum :: Color4 white = { 1.f , 1.f , 1.f , 1.f }; // ambient, diffuse, specular auto custom_material = robot_dart :: gui :: magnum :: gs :: Material ( white , white , white , shininess ); # Clear Light material shininess = 1000. white = magnum . Color4 ( 1. , 1. , 1. , 1. ) # ambient, diffuse, specular custom_material = rd . gui . Material ( white , white , white , shininess ) Now you can add on ore more of the following lights: Point Light : C++ Python // Create point light Magnum :: Vector3 position = { 0.f , 0.f , 2.f }; Magnum :: Float intensity = 1.f ; Magnum :: Vector3 attenuation_terms = { 1.f , 0.f , 0.f }; auto point_light = robot_dart :: gui :: magnum :: gs :: create_point_light ( position , custom_material , intensity , attenuation_terms ); graphics -> add_light ( point_light ); # Create point light position = magnum . Vector3 ( 0. , 0. , 2. ) intensity = 1. attenuation_terms = magnum . Vector3 ( 1. , 0. , 0. ) point_light = rd . gui . create_point_light ( position , custom_material , intensity , attenuation_terms ) graphics . add_light ( point_light ) Spot Light : C++ Python // Create spot light Magnum :: Vector3 position = { 0.f , 0.f , 1.f }; Magnum :: Vector3 direction = { -1.f , -1.f , -1.f }; Magnum :: Float intensity = 1.f ; Magnum :: Vector3 attenuation_terms = { 1.f , 0.f , 0.f }; Magnum :: Float spot_exponent = M_PI ; Magnum :: Float spot_cut_off = M_PI / 8 ; auto spot_light = robot_dart :: gui :: magnum :: gs :: create_spot_light ( position , custom_material , direction , spot_exponent , spot_cut_off , intensity , attenuation_terms ); graphics -> add_light ( spot_light ); # Create spot light position = magnum . Vector3 ( 0. , 0. , 1. ) direction = magnum . Vector3 ( - 1 , - 1 , - 1 ) intensity = 1. attenuation_terms = magnum . Vector3 ( 1. , 0. , 0. ) spot_exponent = np . pi spot_cut_off = np . pi / 8 spot_light = rd . gui . create_spot_light ( position , custom_material , direction , spot_exponent , spot_cut_off , intensity , attenuation_terms ) graphics . add_light ( spot_light ) Directional Light : C++ Python // Create directional light Magnum :: Vector3 direction = { -1.f , -1.f , -1.f }; auto directional_light = robot_dart :: gui :: magnum :: gs :: create_directional_light ( direction , custom_material ); graphics -> add_light ( directional_light ); # Create directional light direction = magnum . Vector3 ( - 1 , - 1 , - 1 ) directional_light = rd . gui . create_directional_light ( direction , custom_material ) graphics . add_light ( directional_light )","title":"How can I alter the graphics scene (e.g., change lighting conditions)?"},{"location":"faq/#i-want-to-visualize-a-target-configuration-of-my-robot-is-this-possible","text":"Yes this is possible. RobotDART gives the ability to create a clone of your robot that has no physics, no contacts, just visuals: C++ Python // Add a ghost robot; only visuals, no dynamics, no collision auto ghost = robot -> clone_ghost (); simu . add_robot ( ghost ); # Add a ghost robot; only visuals, no dynamics, no collision ghost = robot . clone_ghost () simu . add_robot ( ghost )","title":"I want to visualize a target configuration of my robot, is this possible?"},{"location":"faq/#how-can-i-control-my-robot","text":"PD control C++ Python // add a PD-controller to the arm // set desired positions Eigen :: VectorXd ctrl = robot_dart :: make_vector ({ 0. , M_PI / 4. , 0. , - M_PI / 4. , 0. , M_PI / 2. , 0. , 0. }); // add the controller to the robot auto controller = std :: make_shared < robot_dart :: control :: PDControl > ( ctrl ); robot -> add_controller ( controller ); controller -> set_pd ( 300. , 50. ); # add a PD-controller to the arm # set desired positions ctrl = [ 0. , np . pi / 4. , 0. , - np . pi / 4. , 0. , np . pi / 2. , 0. , 0. ] # add the controller to the robot controller = rd . PDControl ( ctrl ) robot . add_controller ( controller ) controller . set_pd ( 300. , 50. ) Simple control C++ Python auto controller1 = std :: make_shared < robot_dart :: control :: SimpleControl > ( ctrl ); robot -> add_controller ( controller1 ); controller1 = rd . SimpleControl ( ctrl ) robot . add_controller ( controller1 ) Robot control C++ Python class MyController : public robot_dart :: control :: RobotControl { public : MyController () : robot_dart :: control :: RobotControl () {} MyController ( const Eigen :: VectorXd & ctrl , bool full_control ) : robot_dart :: control :: RobotControl ( ctrl , full_control ) {} MyController ( const Eigen :: VectorXd & ctrl , const std :: vector < std :: string >& dof_names ) : robot_dart :: control :: RobotControl ( ctrl , dof_names ) {} void configure () override { _active = true ; } Eigen :: VectorXd calculate ( double ) override { auto robot = _robot . lock (); Eigen :: VectorXd cmd = 100. * ( _ctrl - robot -> positions ( _controllable_dofs )); return cmd ; } std :: shared_ptr < robot_dart :: control :: RobotControl > clone () const override { return std :: make_shared < MyController > ( * this ); } }; class MyController ( rd . RobotControl ): def __init__ ( self , ctrl , full_control ): rd . RobotControl . __init__ ( self , ctrl , full_control ) def __init__ ( self , ctrl , controllable_dofs ): rd . RobotControl . __init__ ( self , ctrl , controllable_dofs ) def configure ( self ): self . _active = True def calculate ( self , t ): target = np . array ([ self . _ctrl ]) cmd = 100 * ( target - self . robot () . positions ( self . _controllable_dofs )) return cmd [ 0 ] # TO-DO: This is NOT working at the moment! def clone ( self ): return MyController ( self . _ctrl , self . _controllable_dofs )","title":"How can I control my robot ?"},{"location":"faq/#is-there-a-way-to-control-the-simulation-timestep","text":"When creating a RobotDARTSimu object you choose the simulation timestep: C++ Python // choose time step of 0.001 seconds robot_dart :: RobotDARTSimu simu ( 0.001 ); # choose time step of 0.001 seconds simu = rd . RobotDARTSimu ( 0.001 ) which can later be modified by: C++ Python // set timestep to 0.005 and update control frequency(bool) simu . set_timestep ( 0.005 , true ); # set timestep to 0.005 and update control frequency(bool) simu . set_timestep ( 0.005 , True )","title":"Is there a way to control the simulation timestep?"},{"location":"faq/#i-want-to-simulate-a-mars-environment-is-it-possible-to-change-the-gravitational-force-of-the-simulation-environment","text":"Yes you can modify the gravitational forces 3-dimensional vector of the simulation: C++ Python // Set gravitational force of mars Eigen :: Vector3d mars_gravity = { 0. , 0. , -3.721 }; simu . set_gravity ( mars_gravity ); # set gravitational force of mars mars_gravity = [ 0. , 0. , - 3.721 ] simu . set_gravity ( mars_gravity )","title":"I want to simulate a mars environment, is it possible to change the gravitational force of the simulation environment?"},{"location":"faq/#which-collision-detectors-are-available-what-are-their-differences-how-can-i-choose-between-them","text":"DART FCL ODE Bullet Support only basic shapes Full-featured collision detector fully integrated by DART External collision detector of ODE External collision detector of Bullet This is building along with DART This is a required dependency of DART Needs an external library Needs an external library Very fast for small scenes Accurate detailed collisions, but not very fast Fast collision detection (the integration is not complete) Fast and accurate collision detection (works well for wheels as well) We can easily select one of the available collision detectors using the simulator object: C++ Python simu . set_collision_detector ( \"fcl\" ); // collision_detector can be \"dart\", \"fcl\", \"ode\" or \"bullet\" (case does not matter) simu . set_collision_detector ( \"fcl\" ) # collision_detector can be \"dart\", \"fcl\", \"ode\" or \"bullet\" (case does not matter)","title":"Which collision detectors are available? What are their differences? How can I choose between them?"},{"location":"faq/#my-robot-does-not-self-collide-how-can-i-change-this","text":"One possible cause may be the fact that self collision is disabled, you can check and change this: C++ Python if ( ! robot -> self_colliding ()) { std :: cout << \"Self collision is not enabled\" << std :: endl ; // set self collisions to true and adjacent collisions to false robot -> set_self_collision ( true , false ); } if ( not robot . self_colliding ()): print ( \"Self collision is not enabled\" ) # set self collisions to true and adjacent collisions to false robot . set_self_collision ( True , False )","title":"My robot does not self-collide. How can I change this?"},{"location":"faq/#how-can-i-compute-kinematicdynamic-properties-of-my-robot-eg-jacobians-mass-matrix","text":"Kinematic Properties: C++ Python // Get Joint Positions(Angles) auto joint_positions = robot -> positions (); // Get Joint Velocities auto joint_vels = robot -> velocities (); // Get Joint Accelerations auto joint_accs = robot -> accelerations (); // Get link_name(str) Transformation matrix with respect to the world frame. auto eef_tf = robot -> body_pose ( link_name ); // Get translation vector from transformation matrix auto eef_pos = eef_tf . translation (); // Get rotation matrix from tranformation matrix auto eef_rot = eef_tf . rotation (); // Get link_name 6d pose vector [logmap(eef_tf.linear()), eef_tf.translation()] auto eef_pose_vec = robot -> body_pose_vec ( link_name ); // Get link_name 6d velocity vector [angular, cartesian] auto eef_vel = robot -> body_velocity ( link_name ); // Get link_name 6d acceleration vector [angular, cartesian] auto eef_acc = robot -> body_acceleration ( link_name ); // Jacobian targeting the origin of link_name(str) auto jacobian = robot -> jacobian ( link_name ); // Jacobian time derivative auto jacobian_deriv = robot -> jacobian_deriv ( link_name ); // Center of Mass Jacobian auto com_jacobian = robot -> com_jacobian (); // Center of Mass Jacobian Time Derivative auto com_jacobian_deriv = robot -> com_jacobian_deriv (); # Get Joint Positions(Angles) joint_positions = robot . positions () # Get Joint Velocities joint_vels = robot . velocities () # Get Joint Accelerations joint_accs = robot . accelerations () # Get link_name(str) Transformation matrix with respect to the world frame. eef_tf = robot . body_pose ( link_name ) # Get translation vector from transformation matrix eef_pos = eef_tf . translation () # Get rotation matrix from tranformation matrix eef_rot = eef_tf . rotation () # Get link_name 6d pose vector [logmap(eef_tf.linear()), eef_tf.translation()] eef_pose_vec = robot . body_pose_vec ( link_name ) # Get link_name 6d velocity vector [angular, cartesian] eef_vel = robot . body_velocity ( link_name ) # Get link_name 6d acceleration vector [angular, cartesian] eef_acc = robot . body_acceleration ( link_name ) # Jacobian targeting the origin of link_name(str) jacobian = robot . jacobian ( link_name ) # Jacobian time derivative jacobian_deriv = robot . jacobian_deriv ( link_name ) # Center of Mass Jacobian com_jacobian = robot . com_jacobian () # Center of Mass Jacobian Time Derivative com_jacobian_deriv = robot . com_jacobian_deriv () Dynamic Properties: C++ Python // Get Joint Forces auto joint_forces = robot -> forces (); // Get link's mass auto eef_mass = robot -> body_mass ( link_name ); // Mass Matrix of robot auto mass_matrix = robot -> mass_matrix (); // Inverse of Mass Matrix auto inv_mass_matrix = robot -> inv_mass_matrix (); // Augmented Mass matrix auto aug_mass_matrix = robot -> aug_mass_matrix (); // Inverse of Augmented Mass matrix auto inv_aug_mass_matrix = robot -> inv_aug_mass_matrix (); // Coriolis Force vector auto coriolis = robot -> coriolis_forces (); // Gravity Force vector auto gravity = robot -> gravity_forces (); // Combined vector of Coriolis Force and Gravity Force auto coriolis_gravity = robot -> coriolis_gravity_forces (); // Constraint Force Vector auto constraint_forces = robot -> constraint_forces (); # Get Joint Forces joint_forces = robot . forces () # Get link's mass eef_mass = robot . body_mass ( link_name ) # Mass Matrix of robot mass_matrix = robot . mass_matrix () # Inverse of Mass Matrix inv_mass_matrix = robot . inv_mass_matrix () # Augmented Mass matrix aug_mass_matrix = robot . aug_mass_matrix () # Inverse of Augmented Mass matrix inv_aug_mass_matrix = robot . inv_aug_mass_matrix () # Coriolis Force vector coriolis = robot . coriolis_forces () # Gravity Force vector gravity = robot . gravity_forces () # Combined vector of Coriolis Force and Gravity Force coriolis_gravity = robot . coriolis_gravity_forces () # NOT IMPLEMENTED # # Constraint Force Vector # constraint_forces = robot.constraint_forces()","title":"How can I compute kinematic/dynamic properties of my robot (e.g., Jacobians, Mass Matrix)?"},{"location":"faq/#is-there-a-way-to-change-the-joint-or-link-body-properties-eg-actuation-mass","text":"There are 6 types of actuators available, you can set the same actuator to multiple joints at once, or you can set each sensor separately: C++ Python // Set all DoFs to same actuator robot -> set_actuator_types ( \"servo\" ); // actuator types can be \"servo\", \"torque\", \"velocity\", \"passive\", \"locked\", \"mimic\" // You can also set actuator types separately robot -> set_actuator_type ( \"torque\" , \"iiwa_joint_5\" ); # Set all DoFs to same actuator # actuator types can be \"servo\", \"torque\", \"velocity\", \"passive\", \"locked\", \"mimic\" robot . set_actuator_types ( \"servo\" ) # You can also set actuator types separately robot . set_actuator_type ( \"torque\" , \"iiwa_joint_5\" ) To enable position and velocity limits for the actuators: C++ Python // \u0395nforce joint position and velocity limits robot -> set_position_enforced ( true ); # \u0395nforce joint position and velocity limits robot . set_position_enforced ( True ) Every DOF's limits (position, velocity, acceleration, force) can be modified: C++ Python // Modify Position Limits Eigen :: VectorXd pos_upper_lims ( 7 ); pos_upper_lims << 2.096 , 2.096 , 2.096 , 2.096 , 2.096 , 2.096 , 2.096 ; robot -> set_position_upper_limits ( pos_upper_lims , dof_names ); robot -> set_position_lower_limits ( - pos_upper_lims , dof_names ); // Modify Velocity Limits Eigen :: VectorXd vel_upper_lims ( 7 ); vel_upper_lims << 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 ; robot -> set_velocity_upper_limits ( vel_upper_lims , dof_names ); robot -> set_velocity_lower_limits ( - vel_upper_lims , dof_names ); // Modify Force Limits Eigen :: VectorXd force_upper_lims ( 7 ); force_upper_lims << 150 , 150 , 150 , 150 , 150 , 150 , 150 ; robot -> set_force_upper_limits ( force_upper_lims , dof_names ); robot -> set_force_lower_limits ( - force_upper_lims , dof_names ); // Modify Acceleration Limits Eigen :: VectorXd acc_upper_lims ( 7 ); acc_upper_lims << 1500 , 1500 , 1500 , 1500 , 1500 , 1500 , 1500 ; robot -> set_acceleration_upper_limits ( acc_upper_lims , dof_names ); robot -> set_acceleration_lower_limits ( - acc_upper_lims , dof_names ); # Modify Position Limits pos_upper_lims = np . array ([ 2.096 , 2.096 , 2.096 , 2.096 , 2.096 , 2.096 , 2.096 ]) robot . set_position_upper_limits ( pos_upper_lims , dof_names ) robot . set_position_lower_limits ( - 1 * pos_upper_lims , dof_names ) # Modify Velocity Limits vel_upper_lims = np . array ([ 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 , 1.5 ]) robot . set_velocity_upper_limits ( vel_upper_lims , dof_names ) robot . set_velocity_lower_limits ( - 1 * vel_upper_lims , dof_names ) # Modify Force Limits force_upper_lims = np . array ([ 150 , 150 , 150 , 150 , 150 , 150 , 150 ]) robot . set_force_upper_limits ( force_upper_lims , dof_names ) robot . set_force_lower_limits ( - 1 * force_upper_lims , dof_names ) # Modify Acceleration Limits acc_upper_lims = np . array ([ 1500 , 1500 , 1500 , 1500 , 1500 , 1500 , 1500 ]) robot . set_acceleration_upper_limits ( acc_upper_lims , dof_names ) robot . set_acceleration_lower_limits ( - 1 * acc_upper_lims , dof_names ) You can also modify the damping coefficients, coulomb frictions and spring stiffness of every DOF: C++ Python // Modify Damping Coefficients std :: vector < double > damps = { 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 }; robot -> set_damping_coeffs ( damps , dof_names ); // Modify Coulomb Frictions std :: vector < double > cfrictions = { 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 }; robot -> set_coulomb_coeffs ( cfrictions , dof_names ); // Modify Spring Stiffness std :: vector < double > stiffnesses = { 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 }; robot -> set_spring_stiffnesses ( stiffnesses , dof_names ); # Modify Damping Coefficients damps = [ 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 ] robot . set_damping_coeffs ( damps , dof_names ) # Modify Coulomb Frictions cfrictions = [ 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 ] robot . set_coulomb_coeffs ( cfrictions , dof_names ) # Modify Spring Stiffness stiffnesses = [ 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 , 0.001 ] robot . set_spring_stiffnesses ( stiffnesses , dof_names )","title":"Is there a way to change the joint or link (body) properties (e.g., actuation, mass)?"},{"location":"faq/#what-are-the-supported-sensors-how-can-i-use-an-imu","text":"Sensors in RobotDART can be added only through the simulator object. All of the sensors can be added without being attached to any body or joint but some of them can operate only when attached to something (e.g. ForceTorque sensors).","title":"What are the supported sensors? How can I use an IMU?"},{"location":"faq/#torque-sensor","text":"Torque sensors can be added to every joint of the robot: // Add torque sensors to the robot int ct = 0 ; std :: vector < std :: shared_ptr < robot_dart :: sensor :: Torque >> tq_sensors ( robot -> num_dofs ()); for ( const auto & joint : robot -> dof_names ()) tq_sensors [ ct ++ ] = simu . add_sensor < robot_dart :: sensor :: Torque > ( robot , joint , 1000 ); Torque sensors measure the torque \\(\\tau \\in \\rm I\\!R^n\\) of the attached joint (where \\(n\\) is the DOFs of the joint): // vector that contains the torque measurement for every joint (scalar) Eigen :: VectorXd torques_measure ( robot -> num_dofs ()); for ( const auto & tq_sens : tq_sensors ) torques_measure . block < 1 , 1 > ( ct ++ , 0 ) = tq_sens -> torques ();","title":"Torque sensor"},{"location":"faq/#force-torque-sensor","text":"Force-Torque sensors can be added to every joint of the robot: // Add force-torque sensors to the robot ct = 0 ; std :: vector < std :: shared_ptr < robot_dart :: sensor :: ForceTorque >> f_tq_sensors ( robot -> num_dofs ()); for ( const auto & joint : robot -> dof_names ()) f_tq_sensors [ ct ++ ] = simu . add_sensor < robot_dart :: sensor :: ForceTorque > ( robot , joint , 1000 , \"parent_to_child\" ); Torque sensors measure the force \\(\\boldsymbol{F} \\in \\rm I\\!R^3\\) , the torque \\(\\boldsymbol{\\tau} \\in \\rm I\\!R^3\\) and the wrench \\(\\boldsymbol{\\mathcal{F}} =\\begin{bmatrix} \\tau, F\\end{bmatrix}\\in \\rm I\\!R^6\\) of the attached joint: // matrix that contains the torque measurement for every joint (3d vector) Eigen :: MatrixXd ft_torques_measure ( robot -> num_dofs (), 3 ); // matrix that contains the force measurement for every joint (3d vector) Eigen :: MatrixXd ft_forces_measure ( robot -> num_dofs (), 3 ); // matrix that contains the wrench measurement for every joint (6d vector)[torque, force] Eigen :: MatrixXd ft_wrench_measure ( robot -> num_dofs (), 6 ); ct = 0 ; for ( const auto & f_tq_sens : f_tq_sensors ) { ft_torques_measure . block < 1 , 3 > ( ct , 0 ) = f_tq_sens -> torque (); ft_forces_measure . block < 1 , 3 > ( ct , 0 ) = f_tq_sens -> force (); ft_wrench_measure . block < 1 , 6 > ( ct , 0 ) = f_tq_sens -> wrench (); ct ++ ; }","title":"Force-Torque sensor"},{"location":"faq/#imu-sensor","text":"IMU sensors can be added to every link of the robot: // Add IMU sensors to the robot ct = 0 ; std :: vector < std :: shared_ptr < robot_dart :: sensor :: IMU >> imu_sensors ( robot -> num_bodies ()); for ( const auto & body_node : robot -> body_names ()) { // _imu(std::make_shared<sensor::IMU>(sensor::IMUConfig(body_node(\"head\"), frequency))), imu_sensors [ ct ++ ] = simu . add_sensor < robot_dart :: sensor :: IMU > ( robot_dart :: sensor :: IMUConfig ( robot -> body_node ( body_node ), 1000 )); } IMU sensors measure the angular position vector \\(\\boldsymbol{\\theta} \\in \\rm I\\!R^3\\) , the angular velocity \\(\\boldsymbol{\\omega} \\in \\rm I\\!R^3\\) and the linear acceleration \\(\\boldsymbol{\\alpha} \\in \\rm I\\!R^3\\) of the attached link: Eigen :: MatrixXd imu_angular_positions_measure ( robot -> num_bodies (), 3 ); Eigen :: MatrixXd imu_angular_velocities_measure ( robot -> num_bodies (), 3 ); Eigen :: MatrixXd imu_linear_acceleration_measure ( robot -> num_bodies (), 3 ); ct = 0 ; for ( const auto & imu_sens : imu_sensors ) { imu_angular_positions_measure . block < 1 , 3 > ( ct , 0 ) = imu_sens -> angular_position_vec (); imu_angular_velocities_measure . block < 1 , 3 > ( ct , 0 ) = imu_sens -> angular_velocity (); imu_linear_acceleration_measure . block < 1 , 3 > ( ct , 0 ) = imu_sens -> linear_acceleration (); ct ++ ; }","title":"IMU sensor"},{"location":"faq/#rgb-sensor","text":"Any camera can be used as an RGB sensor: // a nested std::vector (w*h*3) of the last image taken can be retrieved auto rgb_image = camera -> image (); We can easily save the image and/or transform it to grayscale: // we can also save them to png robot_dart :: gui :: save_png_image ( \"camera-small.png\" , rgb_image ); // convert an rgb image to grayscale (useful in some cases) auto gray_image = robot_dart :: gui :: convert_rgb_to_grayscale ( rgb_image ); robot_dart :: gui :: save_png_image ( \"camera-gray.png\" , gray_image );","title":"RGB sensor"},{"location":"faq/#rgb_d-sensor","text":"Any camera can also be configured to also record depth: camera -> camera (). record ( true , true ); // cameras are recording color images by default, enable depth images as well for this example We can then read the RGB and depth images: // get the depth image from a camera // with a version for visualization or bigger differences in the output auto rgb_d_image = camera -> depth_image (); // and the raw values that can be used along with the camera parameters to transform the image to point-cloud auto rgb_d_image_raw = camera -> raw_depth_image (); We can save the depth images as well: robot_dart :: gui :: save_png_image ( \"camera-depth.png\" , rgb_d_image ); robot_dart :: gui :: save_png_image ( \"camera-depth-raw.png\" , rgb_d_image_raw );","title":"RGB_D sensor"},{"location":"faq/#how-can-i-measure-forces-being-applied-to-my-robot","text":"","title":"How can I measure forces being applied to my robot?"},{"location":"faq/#how-can-i-spawn-multiple-robots-in-parallel","text":"The best way to do so is to create a Robot pool. With a robot pool you: Minimize the overhead of loading robots (it happens only once!) or cloning robots (it never happens) Make sure that your robots are \"clean\" once released from each thread Focus on the important stuff rather than handling robots and threads Let's see a more practical example: First we need to include the proper header: #include <robot_dart/robot_pool.hpp> Then we create a creator function and the pool object: namespace pool { // This function should load one robot: here we load Talos inline std :: shared_ptr < robot_dart :: Robot > robot_creator () { return std :: make_shared < robot_dart :: robots :: Talos > (); } // To create the object we need to pass the robot_creator function and the number of maximum parallel threads robot_dart :: RobotPool robot_pool ( robot_creator , NUM_THREADS ); } // namespace pool The creator function is the function responsible for loading your robot. This should basically look like a standalone code to load or create a robot. Next, we create a few threads that utilize the robots (in your code you might be using OpenMP or TBB): // for the example, we run NUM_THREADS threads of eval_robot() std :: vector < std :: thread > threads ( NUM_THREADS * 2 ); // *2 to see some reuse for ( size_t i = 0 ; i < threads . size (); ++ i ) threads [ i ] = std :: thread ( eval_robot , i ); // eval_robot is the function that uses the robot An example evaluation function: inline void eval_robot ( int i ) { // We get one available robot auto robot = pool :: robot_pool . get_robot (); std :: cout << \"Robot \" << i << \" got [\" << robot -> skeleton () << \"]\" << std :: endl ; /// --- some robot_dart code --- simulate_robot ( robot ); // --- do something with the result std :: cout << \"End of simulation \" << i << std :: endl ; // CRITICAL : free your robot ! pool :: robot_pool . free_robot ( robot ); std :: cout << \"Robot \" << i << \" freed!\" << std :: endl ; }","title":"How can I spawn multiple robots in parallel?"},{"location":"faq/#i-need-to-simulate-many-worlds-with-camera-sensors-in-parallel-how-can-i-do-this","text":"On magnum_contexts.cpp you can find an example showcasing the use of many worlds with camera sensors in parallel. The main takeaway is that we need to pre-allocate OpenGL contexts so that each thread can take one and use it to render their worlds. // Load robot from URDF auto global_robot = std :: make_shared < robot_dart :: robots :: Iiwa > (); std :: vector < std :: thread > workers ; // Set maximum number of parallel GL contexts (this is GPU-dependent) robot_dart :: gui :: magnum :: GlobalData :: instance () -> set_max_contexts ( 4 ); // We want 15 parallel simulations with different GL context each size_t N_workers = 15 ; std :: mutex mutex ; size_t id = 0 ; // Launch the workers for ( size_t i = 0 ; i < N_workers ; i ++ ) { workers . push_back ( std :: thread ([ & ] { mutex . lock (); size_t index = id ++ ; mutex . unlock (); // Get the GL context -- this is a blocking call // will wait until one GL context is available // get_gl_context(gl_context); // this call will not sleep between failed queries get_gl_context_with_sleep ( gl_context , 20 ); // this call will sleep 20ms between each failed query // Do the simulation auto robot = global_robot -> clone (); robot_dart :: RobotDARTSimu simu ( 0.001 ); Eigen :: VectorXd ctrl = robot_dart :: make_vector ({ 0. , M_PI / 3. , 0. , - M_PI / 4. , 0. , 0. , 0. }); auto controller = std :: make_shared < robot_dart :: control :: PDControl > ( ctrl ); robot -> add_controller ( controller ); controller -> set_pd ( 300. , 50. ); // Magnum graphics robot_dart :: gui :: magnum :: GraphicsConfiguration configuration = robot_dart :: gui :: magnum :: WindowlessGraphics :: default_configuration (); configuration . width = 1024 ; configuration . height = 768 ; auto graphics = std :: make_shared < robot_dart :: gui :: magnum :: WindowlessGraphics > ( configuration ); simu . set_graphics ( graphics ); // Position the camera differently for each thread to visualize the difference graphics -> look_at ({ 0.4 * index , 3.5 - index * 0.1 , 2. }, { 0. , 0. , 0.25 }); // record images from main camera/graphics // graphics->set_recording(true); // WindowlessGLApplication records images by default simu . add_robot ( robot ); simu . run ( 6 ); // Save the image for verification robot_dart :: gui :: save_png_image ( \"camera_\" + std :: to_string ( index ) + \".png\" , graphics -> image ()); // Release the GL context for another thread to use release_gl_context ( gl_context ); })); } // Wait for all the workers for ( size_t i = 0 ; i < workers . size (); i ++ ) { workers [ i ]. join (); }","title":"I need to simulate many worlds with camera sensors in parallel. How can I do this?"},{"location":"faq/#i-do-not-know-how-to-use-waf-how-can-i-detect-robotdart-from-cmake","text":"You need to use waf to build RobotDART, but when installing the library a CMake module is installed. Thus it is possible use RobotDART in your code using CMake. You can find a complete example at cmake/example . In short the CMake would look like this: cmake_minimum_required ( VERSION 3.10 FATAL_ERROR ) project ( robot_dart_example ) # we ask for Magnum because we want to build the graphics find_package ( RobotDART REQUIRED OPTIONAL_COMPONENTS Magnum ) add_executable ( robot_dart_example example.cpp ) target_link_libraries ( robot_dart_example RobotDART::Simu ) if ( RobotDART_Magnum_FOUND ) add_executable ( robot_dart_example_graphics example.cpp ) target_link_libraries ( robot_dart_example_graphics RobotDART::Simu RobotDART::Magnum ) endif ()","title":"I do not know how to use waf. How can I detect RobotDART from CMake?"},{"location":"faq/#i-prefer-coding-in-python-how-can-i-use-robotdart","text":"RobotDART comes with python bindinds. Please refer to the installation page to see how to install them. Once the python bindings are installed, we can use RobotDART from python! An example is available at example.py . There is mostly an one-to-one mapping between C++ and python objects and functions.","title":"I prefer coding in python. How can I use RobotDART?"},{"location":"install/","text":".md-typeset h1, .md-content__button { display: none; } Manual Installation of RobotDART \u00b6 Dependencies \u00b6 Required \u00b6 Ubuntu (it should work on versions >= 14.04) or OSX Eigen3 (needed by DART) Boost (needed by DART) DART, http://dartsim.github.io/ Optional \u00b6 Magnum (for graphics), https://github.com/mosra/magnum Installation of the dependencies \u00b6 Installing Boost and Eigen3 \u00b6 For Ubuntu-based distributions we should use the following commands to install Eigen3 and Boost: sudo apt-get update sudo apt-get install libeigen3-dev libboost-filesystem-dev libboost-system-dev libboost-regex-dev For OSX with brew: brew install eigen3 brew install boost Installing DART \u00b6 In order to use RobotDART, you need to install DART (from source). For Ubuntu systems , please follow the detailed installation instructions on the DART documentation website . Make sure that you don't forget to add the PPAs as detailed here . What is more, you can enable the -DART_ENABLE_SIMD flag in the CMake configuration. In addition, you need the following optional dependency: DART Parsers . Lastly, it is recommended to use either the master branch or v6.12.1 tag (and not the one provided in DART's documentation). In short you should do the following: Ubuntu <= 14.04 only sudo apt-add-repository ppa:libccd-debs/ppa sudo apt-add-repository ppa:fcl-debs/ppa For all Ubuntu distributions sudo apt-add-repository ppa:dartsim/ppa sudo apt-get update sudo apt-get install build-essential cmake pkg-config git sudo apt-get install libeigen3-dev libassimp-dev libccd-dev libfcl-dev libboost-regex-dev libboost-system-dev sudo apt-get install libtinyxml-dev libtinyxml2-dev sudo apt-get install liburdfdom-dev liburdfdom-headers-dev cd /path/to/tmp/folder git clone git://github.com/dartsim/dart.git cd dart git checkout v6.12.1 mkdir build cd build cmake -DCMAKE_BUILD_TYPE = Release -DCMAKE_INSTALL_PREFIX = /usr .. make -j4 sudo make install If you want to install DART somewhere else than /usr/local , you should use the -DCMAKE_INSTALL_PREFIX=/path/to/install/folder cmake argument. For OSX systems with homebrew, please follow the detailed installation instructions on the DART documentation website . You need to follow the same procedure as for Ubuntu systems. In short you should do the following: brew install eigen brew install assimp brew install libccd brew install dartsim/dart/fcl04 brew install boost brew install tinyxml brew install tinyxml2 brew install urdfdom cd /path/to/tmp/folder git clone git://github.com/dartsim/dart.git cd dart git checkout v6.12.1 mkdir build cd build cmake -DCMAKE_BUILD_TYPE = Release -DCMAKE_INSTALL_PREFIX = /usr .. make -j4 sudo make install Installing Magnum \u00b6 Magnum depends on Corrade and we are going to use a few plugins and extras from the library. We are also going to use Glfw and Glx for the back-end. Follow the instrutions below: #installation of Glfw and OpenAL # Ubuntu sudo apt-get install libglfw3-dev libglfw3 libopenal-dev libassimp-dev # Mac OSX brew install glfw3 openal-soft assimp # installation of Corrade cd /path/to/tmp/folder git clone https://github.com/mosra/corrade.git cd corrade mkdir build && cd build cmake -DCMAKE_BUILD_TYPE = Release .. make -j sudo make install # installation of Magnum cd /path/to/tmp/folder git clone https://github.com/mosra/magnum.git cd magnum mkdir build && cd build # Ubuntu cmake -DCMAKE_BUILD_TYPE = Release -DWITH_AUDIO = ON -DWITH_DEBUGTOOLS = ON -DWITH_GL = ON -DWITH_MESHTOOLS = ON -DWITH_PRIMITIVES = ON -DWITH_SCENEGRAPH = ON -DWITH_SHADERS = ON -DWITH_TEXT = ON -DWITH_TEXTURETOOLS = ON -DWITH_TRADE = ON -DWITH_GLFWAPPLICATION = ON -DWITH_WINDOWLESSGLXAPPLICATION = ON -DWITH_OPENGLTESTER = ON -DWITH_ANYAUDIOIMPORTER = ON -DWITH_ANYIMAGECONVERTER = ON -DWITH_ANYIMAGEIMPORTER = ON -DWITH_ANYSCENEIMPORTER = ON -DWITH_MAGNUMFONT = ON -DWITH_OBJIMPORTER = ON -DWITH_TGAIMPORTER = ON -DWITH_WAVAUDIOIMPORTER = ON .. # this will enable almost all features of Magnum that are not necessarily needed for robot_dart (please refer to the documentation of Magnum for more details on selecting only the ones that you need) # Mac OSX cmake -DCMAKE_BUILD_TYPE = Release -DWITH_AUDIO = ON -DWITH_DEBUGTOOLS = ON -DWITH_GL = ON -DWITH_MESHTOOLS = ON -DWITH_PRIMITIVES = ON -DWITH_SCENEGRAPH = ON -DWITH_SHADERS = ON -DWITH_TEXT = ON -DWITH_TEXTURETOOLS = ON -DWITH_TRADE = ON -DWITH_GLFWAPPLICATION = ON -DWITH_WINDOWLESSCGLAPPLICATION = ON -DWITH_OPENGLTESTER = ON -DWITH_ANYAUDIOIMPORTER = ON -DWITH_ANYIMAGECONVERTER = ON -DWITH_ANYIMAGEIMPORTER = ON -DWITH_ANYSCENEIMPORTER = ON -DWITH_MAGNUMFONT = ON -DWITH_OBJIMPORTER = ON -DWITH_TGAIMPORTER = ON -DWITH_WAVAUDIOIMPORTER = ON .. # this will enable almost all features of Magnum that are not necessarily needed for robot_dart (please refer to the documentation of Magnum for more details on selecting only the ones that you need) make -j sudo make install # installation of Magnum Plugins cd /path/to/tmp/folder git clone https://github.com/mosra/magnum-plugins.git cd magnum-plugins mkdir build && cd build cmake -DCMAKE_BUILD_TYPE = Release -DWITH_ASSIMPIMPORTER = ON -DWITH_DDSIMPORTER = ON -DWITH_JPEGIMPORTER = ON -DWITH_OPENGEXIMPORTER = ON -DWITH_PNGIMPORTER = ON -DWITH_TINYGLTFIMPORTER = ON -DWITH_STBTRUETYPEFONT = ON .. # this will enable quite a few Magnum Plugins that are not necessarily needed for robot_dart (please refer to the documentation of Magnum for more details on selecting only the ones that you need) make -j sudo make install # installation of Magnum DART Integration (DART needs to be installed) and Eigen Integration cd /path/to/tmp/folder git clone https://github.com/mosra/magnum-integration.git cd magnum-integration mkdir build && cd build cmake -DCMAKE_BUILD_TYPE = Release -DWITH_DART = ON -DWITH_EIGEN = ON .. make -j sudo make install Compilation and running the examples \u00b6 The compilation of the library is straight-forward: retrieve the code, for instance with git clone https://github.com/resibots/robot_dart.git cd /path/to/repo/root ./waf configure ./waf To build the examples, execute this: ./waf examples Now you can run the examples. For example, to run the arm example you need to type the following: ./build/arm (or ./build/arm_plain to run it without graphics). Installing the library \u00b6 To install the library (assuming that you have already compiled it), you need only to run: ./waf install By default the library will be installed in /usr/local/lib (for this maybe sudo ./waf install might be needed) and a static library will be generated. You can change the defaults as follows: ./waf configure --prefix=/path/to/install/dir --shared ./waf install In short, with --prefix you can change the directory where the library will be installed and if --shared is present a shared library will be created instead of a static one. Compiling the python bindings \u00b6 For the python bindings of robot_dart, we need numpy to be installed, pybind11 and the python bindings of DART (dartpy). For numpy one can install it with pip or standard packages. For pybind11 please follow the instructions on the dart website (focus on the pybind11 part, for the other parts follow our instructions above). For the python bindings of DART, do: cd dart mkdir build cd build cmake -DDART_BUILD_DARTPY = ON -DCMAKE_BUILD_TYPE = Release -DCMAKE_INSTALL_PREFIX = /usr .. make -j4 sudo make install sudo make install-dartpy # for DART >= v6.12.0, we do not need this Then the compilation of robot_dart is almost identical as before: retrieve the code, for instance with git clone https://github.com/resibots/robot_dart.git cd /path/to/repo/root ./waf configure --python ( --python enables the python bindings) ./waf Install the library (including the python bindings) as before (no change is needed) Depending on your installation directory you might need to update your PYTHONPATH , e.g. export PYTHONPATH=$PYTHONPATH:/usr/local/lib/python3.8/site-packages/ To run the python examples (for the python examples you need to have enabled the graphics, that is, install Magnum library), run: cd /path/to/repo/root python src/python/example.py or python src/python/example_parallel.py Common Issues with Python bindings \u00b6 One of the most common issue with the python bindings is the fact that DART bindings might be compiled and installed for python 3 and the robot_dart ones for python 2. To force the usage of python 3 for robot_dart, you use python3 ./waf instead of just ./waf in all the commands above.","title":"Manual Installation"},{"location":"install/#manual-installation-of-robotdart","text":"","title":"Manual Installation of RobotDART"},{"location":"install/#dependencies","text":"","title":"Dependencies"},{"location":"install/#required","text":"Ubuntu (it should work on versions >= 14.04) or OSX Eigen3 (needed by DART) Boost (needed by DART) DART, http://dartsim.github.io/","title":"Required"},{"location":"install/#optional","text":"Magnum (for graphics), https://github.com/mosra/magnum","title":"Optional"},{"location":"install/#installation-of-the-dependencies","text":"","title":"Installation of the dependencies"},{"location":"install/#installing-boost-and-eigen3","text":"For Ubuntu-based distributions we should use the following commands to install Eigen3 and Boost: sudo apt-get update sudo apt-get install libeigen3-dev libboost-filesystem-dev libboost-system-dev libboost-regex-dev For OSX with brew: brew install eigen3 brew install boost","title":"Installing Boost and Eigen3"},{"location":"install/#installing-dart","text":"In order to use RobotDART, you need to install DART (from source). For Ubuntu systems , please follow the detailed installation instructions on the DART documentation website . Make sure that you don't forget to add the PPAs as detailed here . What is more, you can enable the -DART_ENABLE_SIMD flag in the CMake configuration. In addition, you need the following optional dependency: DART Parsers . Lastly, it is recommended to use either the master branch or v6.12.1 tag (and not the one provided in DART's documentation). In short you should do the following: Ubuntu <= 14.04 only sudo apt-add-repository ppa:libccd-debs/ppa sudo apt-add-repository ppa:fcl-debs/ppa For all Ubuntu distributions sudo apt-add-repository ppa:dartsim/ppa sudo apt-get update sudo apt-get install build-essential cmake pkg-config git sudo apt-get install libeigen3-dev libassimp-dev libccd-dev libfcl-dev libboost-regex-dev libboost-system-dev sudo apt-get install libtinyxml-dev libtinyxml2-dev sudo apt-get install liburdfdom-dev liburdfdom-headers-dev cd /path/to/tmp/folder git clone git://github.com/dartsim/dart.git cd dart git checkout v6.12.1 mkdir build cd build cmake -DCMAKE_BUILD_TYPE = Release -DCMAKE_INSTALL_PREFIX = /usr .. make -j4 sudo make install If you want to install DART somewhere else than /usr/local , you should use the -DCMAKE_INSTALL_PREFIX=/path/to/install/folder cmake argument. For OSX systems with homebrew, please follow the detailed installation instructions on the DART documentation website . You need to follow the same procedure as for Ubuntu systems. In short you should do the following: brew install eigen brew install assimp brew install libccd brew install dartsim/dart/fcl04 brew install boost brew install tinyxml brew install tinyxml2 brew install urdfdom cd /path/to/tmp/folder git clone git://github.com/dartsim/dart.git cd dart git checkout v6.12.1 mkdir build cd build cmake -DCMAKE_BUILD_TYPE = Release -DCMAKE_INSTALL_PREFIX = /usr .. make -j4 sudo make install","title":"Installing DART"},{"location":"install/#installing-magnum","text":"Magnum depends on Corrade and we are going to use a few plugins and extras from the library. We are also going to use Glfw and Glx for the back-end. Follow the instrutions below: #installation of Glfw and OpenAL # Ubuntu sudo apt-get install libglfw3-dev libglfw3 libopenal-dev libassimp-dev # Mac OSX brew install glfw3 openal-soft assimp # installation of Corrade cd /path/to/tmp/folder git clone https://github.com/mosra/corrade.git cd corrade mkdir build && cd build cmake -DCMAKE_BUILD_TYPE = Release .. make -j sudo make install # installation of Magnum cd /path/to/tmp/folder git clone https://github.com/mosra/magnum.git cd magnum mkdir build && cd build # Ubuntu cmake -DCMAKE_BUILD_TYPE = Release -DWITH_AUDIO = ON -DWITH_DEBUGTOOLS = ON -DWITH_GL = ON -DWITH_MESHTOOLS = ON -DWITH_PRIMITIVES = ON -DWITH_SCENEGRAPH = ON -DWITH_SHADERS = ON -DWITH_TEXT = ON -DWITH_TEXTURETOOLS = ON -DWITH_TRADE = ON -DWITH_GLFWAPPLICATION = ON -DWITH_WINDOWLESSGLXAPPLICATION = ON -DWITH_OPENGLTESTER = ON -DWITH_ANYAUDIOIMPORTER = ON -DWITH_ANYIMAGECONVERTER = ON -DWITH_ANYIMAGEIMPORTER = ON -DWITH_ANYSCENEIMPORTER = ON -DWITH_MAGNUMFONT = ON -DWITH_OBJIMPORTER = ON -DWITH_TGAIMPORTER = ON -DWITH_WAVAUDIOIMPORTER = ON .. # this will enable almost all features of Magnum that are not necessarily needed for robot_dart (please refer to the documentation of Magnum for more details on selecting only the ones that you need) # Mac OSX cmake -DCMAKE_BUILD_TYPE = Release -DWITH_AUDIO = ON -DWITH_DEBUGTOOLS = ON -DWITH_GL = ON -DWITH_MESHTOOLS = ON -DWITH_PRIMITIVES = ON -DWITH_SCENEGRAPH = ON -DWITH_SHADERS = ON -DWITH_TEXT = ON -DWITH_TEXTURETOOLS = ON -DWITH_TRADE = ON -DWITH_GLFWAPPLICATION = ON -DWITH_WINDOWLESSCGLAPPLICATION = ON -DWITH_OPENGLTESTER = ON -DWITH_ANYAUDIOIMPORTER = ON -DWITH_ANYIMAGECONVERTER = ON -DWITH_ANYIMAGEIMPORTER = ON -DWITH_ANYSCENEIMPORTER = ON -DWITH_MAGNUMFONT = ON -DWITH_OBJIMPORTER = ON -DWITH_TGAIMPORTER = ON -DWITH_WAVAUDIOIMPORTER = ON .. # this will enable almost all features of Magnum that are not necessarily needed for robot_dart (please refer to the documentation of Magnum for more details on selecting only the ones that you need) make -j sudo make install # installation of Magnum Plugins cd /path/to/tmp/folder git clone https://github.com/mosra/magnum-plugins.git cd magnum-plugins mkdir build && cd build cmake -DCMAKE_BUILD_TYPE = Release -DWITH_ASSIMPIMPORTER = ON -DWITH_DDSIMPORTER = ON -DWITH_JPEGIMPORTER = ON -DWITH_OPENGEXIMPORTER = ON -DWITH_PNGIMPORTER = ON -DWITH_TINYGLTFIMPORTER = ON -DWITH_STBTRUETYPEFONT = ON .. # this will enable quite a few Magnum Plugins that are not necessarily needed for robot_dart (please refer to the documentation of Magnum for more details on selecting only the ones that you need) make -j sudo make install # installation of Magnum DART Integration (DART needs to be installed) and Eigen Integration cd /path/to/tmp/folder git clone https://github.com/mosra/magnum-integration.git cd magnum-integration mkdir build && cd build cmake -DCMAKE_BUILD_TYPE = Release -DWITH_DART = ON -DWITH_EIGEN = ON .. make -j sudo make install","title":"Installing Magnum"},{"location":"install/#compilation-and-running-the-examples","text":"The compilation of the library is straight-forward: retrieve the code, for instance with git clone https://github.com/resibots/robot_dart.git cd /path/to/repo/root ./waf configure ./waf To build the examples, execute this: ./waf examples Now you can run the examples. For example, to run the arm example you need to type the following: ./build/arm (or ./build/arm_plain to run it without graphics).","title":"Compilation and running the examples"},{"location":"install/#installing-the-library","text":"To install the library (assuming that you have already compiled it), you need only to run: ./waf install By default the library will be installed in /usr/local/lib (for this maybe sudo ./waf install might be needed) and a static library will be generated. You can change the defaults as follows: ./waf configure --prefix=/path/to/install/dir --shared ./waf install In short, with --prefix you can change the directory where the library will be installed and if --shared is present a shared library will be created instead of a static one.","title":"Installing the library"},{"location":"install/#compiling-the-python-bindings","text":"For the python bindings of robot_dart, we need numpy to be installed, pybind11 and the python bindings of DART (dartpy). For numpy one can install it with pip or standard packages. For pybind11 please follow the instructions on the dart website (focus on the pybind11 part, for the other parts follow our instructions above). For the python bindings of DART, do: cd dart mkdir build cd build cmake -DDART_BUILD_DARTPY = ON -DCMAKE_BUILD_TYPE = Release -DCMAKE_INSTALL_PREFIX = /usr .. make -j4 sudo make install sudo make install-dartpy # for DART >= v6.12.0, we do not need this Then the compilation of robot_dart is almost identical as before: retrieve the code, for instance with git clone https://github.com/resibots/robot_dart.git cd /path/to/repo/root ./waf configure --python ( --python enables the python bindings) ./waf Install the library (including the python bindings) as before (no change is needed) Depending on your installation directory you might need to update your PYTHONPATH , e.g. export PYTHONPATH=$PYTHONPATH:/usr/local/lib/python3.8/site-packages/ To run the python examples (for the python examples you need to have enabled the graphics, that is, install Magnum library), run: cd /path/to/repo/root python src/python/example.py or python src/python/example_parallel.py","title":"Compiling the python bindings"},{"location":"install/#common-issues-with-python-bindings","text":"One of the most common issue with the python bindings is the fact that DART bindings might be compiled and installed for python 3 and the robot_dart ones for python 2. To force the usage of python 3 for robot_dart, you use python3 ./waf instead of just ./waf in all the commands above.","title":"Common Issues with Python bindings"},{"location":"quick_install/","text":".md-typeset h1, .md-content__button { display: none; } Scripts for Quick Installation of RobotDART \u00b6 In this page we provide standalone scripts for installing RobotDART for Ubuntu (20.04) and OSX . The scripts will install all the required dependencies and RobotDART. Notably, all dependencies that need to be compiled by source and RobotDART will be installed inside the /opt folder. This way, one can be rest assured that their system will be clean. Ubuntu 20.04 \u00b6 To quickly install RobotDART on Ubuntu 20.04 , we just need to run ./scripts/install_ubuntu.sh from the root of the repo. In more detail: git clone https://github.com/resibots/robot_dart.git cd robot_dart ./scripts/install_ubuntu.sh This will install everything needed! Once the script is successfully executed, one should add the following to their ~/.bashrc or ~/.zshrc file: export PATH = /opt/magnum/bin: $PATH export LD_LIBRARY_PATH = /opt/dart/lib:/opt/magnum/lib:/opt/robot_dart/lib: $LD_LIBRARY_PATH export PYTHONPATH = /opt/dart/lib/python3/dist-packages:/opt/robot_dart/lib/python3.8/site-packages: $PYTHONPATH OSX \u00b6 Coming soon","title":"Installation"},{"location":"quick_install/#scripts-for-quick-installation-of-robotdart","text":"In this page we provide standalone scripts for installing RobotDART for Ubuntu (20.04) and OSX . The scripts will install all the required dependencies and RobotDART. Notably, all dependencies that need to be compiled by source and RobotDART will be installed inside the /opt folder. This way, one can be rest assured that their system will be clean.","title":"Scripts for Quick Installation of RobotDART"},{"location":"quick_install/#ubuntu-2004","text":"To quickly install RobotDART on Ubuntu 20.04 , we just need to run ./scripts/install_ubuntu.sh from the root of the repo. In more detail: git clone https://github.com/resibots/robot_dart.git cd robot_dart ./scripts/install_ubuntu.sh This will install everything needed! Once the script is successfully executed, one should add the following to their ~/.bashrc or ~/.zshrc file: export PATH = /opt/magnum/bin: $PATH export LD_LIBRARY_PATH = /opt/dart/lib:/opt/magnum/lib:/opt/robot_dart/lib: $LD_LIBRARY_PATH export PYTHONPATH = /opt/dart/lib/python3/dist-packages:/opt/robot_dart/lib/python3.8/site-packages: $PYTHONPATH","title":"Ubuntu 20.04"},{"location":"quick_install/#osx","text":"Coming soon","title":"OSX"},{"location":"robots/","text":".md-typeset h1, .md-content__button { display: none; } Supported robots \u00b6 Every robot is a defined as a URDF, which will be installed $PREFIX/share/utheque . All robots have pre-defined \"robot classes\" that define sensors and other properties; for your custom/new robots, you will have to add the sensors/properties via the generic robot class (or create a new robot class). The URDF files are loaded using the following rules (see utheque::path() ): First check in the current directory If not found, check in current_directory/utheque If not found, check in $ROBOT_DART_PATH/utheque If not found, check in the robot dart installation path/robots (e.g., /usr/share/utheque or $HOME/share/utheque ) Otherwise, report failure utheque is a separate header-only library that gets installed together with RobotDART (or even alone), that can be used in libraries that do not want to interfere with RobotDART and use the curated URDF files. Talos (PAL Robotics) \u00b6 Talos is a humanoid robot made by PAL Robotics . Datasheet: [ pdf ] 32 degrees of freedom (6 for each leg, 7 for each arm, 2 for the waist, 2 for the neck, 1 for each gripper) 175 cm / 95 kg IMU in the torso Torque sensors in all joints except head, wrist and gripper (22 torque sensors total) 1 force/torque sensor in each ankle 1 force/torque sensor in each wrist We have two URDF files: robots/talos/talos.urdf : accurate (simplified but made of polygons) collision meshes mimic joints for the gripper Not compatible the DART collision detector (you need to use FCL collision detector - shipped with DART) URDF: [ talos.urdf ] Example: [ talos.cpp ] Load Talos // load talos auto robot = std :: make_shared < robot_dart :: robots :: Talos > (); // Set actuator types to VELOCITY (for speed) robot -> set_actuator_types ( \"velocity\" ); // Enforce limits (ON by default) robot -> set_position_enforced ( true ); double dt = 0.001 ; robot_dart :: RobotDARTSimu simu ( dt ); // must use fcl collision detector simu . set_collision_detector ( \"fcl\" ); robot/talos/talos_fast.urdf : no collision except for the feet, which are approximated by boxes grippers are fixed (no movement is allowed) compatible with the DART collision detector URDF: [ talos_fast.urdf ] Example: [ talos_fast.cpp ] talos_fast.urdf is faster because it makes it possible to use the DART collision detector (and has much collision shapes). You should prefer it except if you want to use the grippers (e.g., for manipulation) or are working on self-collisions. Load Talos Fast // load talos fast auto robot = std :: make_shared < robot_dart :: robots :: TalosFastCollision > (); // Set actuator types to VELOCITY (for speed) robot -> set_actuator_types ( \"velocity\" ); double dt = 0.001 ; robot_dart :: RobotDARTSimu simu ( dt ); // we can use the DART (fast) collision detector simu . set_collision_detector ( \"dart\" ); Please note that the mesh files (.glb) require assimp 5.x (and not assimp4.x usually shipped with ROS). If you cannot load the URDF, please check your assimp version. Panda (Franka Emika) \u00b6 The Franka is a modern manipulator made by Franka Emika Panda . It is commonly found in many robotics labs. Datasheet: [ pdf ] 7 degrees of freedom Can be controlled in torque 18 kg workspace: 855 mm (horizontal), 1190 mm (vertical) URDF: [ franka.urdf ] Example: [ franka.cpp ] The URDF includes the gripper. Load Franka auto robot = std :: make_shared < robot_dart :: robots :: Franka > (); LBR iiwa (KUKA) \u00b6 The LBR iiwa is manufactured by KUKA . It is similar to the Panda and is also very common in robotics labs. Datasheet: [ pdf ] We implement the 14 kg version 29.5 kg 7 degrees of freedom URDF: [ iiwa.urdf ] Example: [ iiwa.cpp ] Load LBR iiwa auto robot = std :: make_shared < robot_dart :: robots :: Iiwa > (); iCub (IIT) \u00b6 The iCub is a open source humanoid robot made by the Instituto Italiano di Tecnologia . There are currently 42 iCUbs in the world, and many versions. Datasheet (rev 2.3) [ pdf ] 6 force/torque sensors (upper arms, upper legs, ankles) IMU in the head We do to simulate the skin We do not simulate the hands Our model is close to the Inria's iCub , but it has not been checked in detail. URDF: [ icub.urdf ] Example [ icub.cpp ] Please note that the mesh files (.glb) require assimp 5.x (and not assimp4.x usually shipped with ROS). If you cannot load the URDF, please check your assimp version. Load iCub auto robot = std :: make_shared < robot_dart :: robots :: ICub > (); // Set actuator types to VELOCITY motors so that they stay in position without any controller robot -> set_actuator_types ( \"velocity\" ); robot_dart :: RobotDARTSimu simu ( 0.001 ); simu . set_collision_detector ( \"fcl\" ); Print IMU sensor measurements std :: cout << \"Angular Position: \" << robot -> imu (). angular_position_vec (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"Angular Velocity: \" << robot -> imu (). angular_velocity (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"Linear Acceleration: \" << robot -> imu (). linear_acceleration (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"=================================\" << std :: endl ; Print Force-Torque sensor measurements std :: cout << \"FT ( force): \" << robot -> ft_foot_left (). force (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"FT (torque): \" << robot -> ft_foot_left (). torque (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"=================================\" << std :: endl ; Unitree A1 \u00b6 A1 is a quadruped robot made by the Unitree Robotics . IMU in the torso We do not simulate the foot pressure sensors (yet) One can easily add a depth camera on the head URDF: [ a1.urdf ] Example [ a1.cpp ] Load A1 auto robot = std :: make_shared < robot_dart :: robots :: A1 > (); Print IMU sensor measurements std :: cout << \"Angular Position: \" << robot -> imu (). angular_position_vec (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"Angular Velocity: \" << robot -> imu (). angular_velocity (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"Linear Acceleration: \" << robot -> imu (). linear_acceleration (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"=================================\" << std :: endl ; Add a depth camera on the head How can I attach a camera to a moving link? Please note that the mesh files (.glb) require assimp 5.x (and not assimp4.x usually shipped with ROS). If you cannot load the URDF, please check your assimp version. Dynamixel-based hexapod robot (Inria and others) \u00b6 This hexapod is a simple 6-legged robot based on dynamixel actuators. It is similar to the robot used in the paper `Robots that can adapt like animals' (Cully et al., 2015). 6 legs, 3 degrees of freedom for each leg (18 degrees of freedom) simple URDF (no meshes) URDF: [ pexod.urdf ] Example: [ hexapod.cpp ] Load Hexapod auto robot = std :: make_shared < robot_dart :: robots :: Hexapod > (); Load Pexod auto robot = std :: make_shared < robot_dart :: Robot > ( \"pexod.urdf\" ); Simple arm \u00b6 A simple arm for educational or debugging purposes 5 degrees of freedom simple URDF (no meshes) URDF: [ arm.urdf ] Example: [ arm.cpp ] Load Simple Arm auto robot = std :: make_shared < robot_dart :: robots :: Arm > (); Loading Custom Robots \u00b6 RobotDART gives you the ability to load custom robots that are defined in URDF , SDF , SKEL or MJCF files. For example, you can load a urdf model using: Load custom Robot auto your_robot = std :: make_shared < robot_dart :: Robot > ( \"path/to/model.urdf\" ); Load custom Robot with packages (e.g STL, DAE meshes) std :: vector < std :: pair < std :: string , std :: string >> your_model_packages = ( ' model ' , ' path / to / model / dir ' ); auto your_robot = std :: make_shared < robot_dart :: Robot > ( \"path/to/model.urdf\" , your_model_packages , \"packages\" );","title":"Supported robots"},{"location":"robots/#supported-robots","text":"Every robot is a defined as a URDF, which will be installed $PREFIX/share/utheque . All robots have pre-defined \"robot classes\" that define sensors and other properties; for your custom/new robots, you will have to add the sensors/properties via the generic robot class (or create a new robot class). The URDF files are loaded using the following rules (see utheque::path() ): First check in the current directory If not found, check in current_directory/utheque If not found, check in $ROBOT_DART_PATH/utheque If not found, check in the robot dart installation path/robots (e.g., /usr/share/utheque or $HOME/share/utheque ) Otherwise, report failure utheque is a separate header-only library that gets installed together with RobotDART (or even alone), that can be used in libraries that do not want to interfere with RobotDART and use the curated URDF files.","title":"Supported robots"},{"location":"robots/#talos-pal-robotics","text":"Talos is a humanoid robot made by PAL Robotics . Datasheet: [ pdf ] 32 degrees of freedom (6 for each leg, 7 for each arm, 2 for the waist, 2 for the neck, 1 for each gripper) 175 cm / 95 kg IMU in the torso Torque sensors in all joints except head, wrist and gripper (22 torque sensors total) 1 force/torque sensor in each ankle 1 force/torque sensor in each wrist We have two URDF files: robots/talos/talos.urdf : accurate (simplified but made of polygons) collision meshes mimic joints for the gripper Not compatible the DART collision detector (you need to use FCL collision detector - shipped with DART) URDF: [ talos.urdf ] Example: [ talos.cpp ] Load Talos // load talos auto robot = std :: make_shared < robot_dart :: robots :: Talos > (); // Set actuator types to VELOCITY (for speed) robot -> set_actuator_types ( \"velocity\" ); // Enforce limits (ON by default) robot -> set_position_enforced ( true ); double dt = 0.001 ; robot_dart :: RobotDARTSimu simu ( dt ); // must use fcl collision detector simu . set_collision_detector ( \"fcl\" ); robot/talos/talos_fast.urdf : no collision except for the feet, which are approximated by boxes grippers are fixed (no movement is allowed) compatible with the DART collision detector URDF: [ talos_fast.urdf ] Example: [ talos_fast.cpp ] talos_fast.urdf is faster because it makes it possible to use the DART collision detector (and has much collision shapes). You should prefer it except if you want to use the grippers (e.g., for manipulation) or are working on self-collisions. Load Talos Fast // load talos fast auto robot = std :: make_shared < robot_dart :: robots :: TalosFastCollision > (); // Set actuator types to VELOCITY (for speed) robot -> set_actuator_types ( \"velocity\" ); double dt = 0.001 ; robot_dart :: RobotDARTSimu simu ( dt ); // we can use the DART (fast) collision detector simu . set_collision_detector ( \"dart\" ); Please note that the mesh files (.glb) require assimp 5.x (and not assimp4.x usually shipped with ROS). If you cannot load the URDF, please check your assimp version.","title":"Talos (PAL Robotics)"},{"location":"robots/#panda-franka-emika","text":"The Franka is a modern manipulator made by Franka Emika Panda . It is commonly found in many robotics labs. Datasheet: [ pdf ] 7 degrees of freedom Can be controlled in torque 18 kg workspace: 855 mm (horizontal), 1190 mm (vertical) URDF: [ franka.urdf ] Example: [ franka.cpp ] The URDF includes the gripper. Load Franka auto robot = std :: make_shared < robot_dart :: robots :: Franka > ();","title":"Panda (Franka Emika)"},{"location":"robots/#lbr-iiwa-kuka","text":"The LBR iiwa is manufactured by KUKA . It is similar to the Panda and is also very common in robotics labs. Datasheet: [ pdf ] We implement the 14 kg version 29.5 kg 7 degrees of freedom URDF: [ iiwa.urdf ] Example: [ iiwa.cpp ] Load LBR iiwa auto robot = std :: make_shared < robot_dart :: robots :: Iiwa > ();","title":"LBR iiwa (KUKA)"},{"location":"robots/#icub-iit","text":"The iCub is a open source humanoid robot made by the Instituto Italiano di Tecnologia . There are currently 42 iCUbs in the world, and many versions. Datasheet (rev 2.3) [ pdf ] 6 force/torque sensors (upper arms, upper legs, ankles) IMU in the head We do to simulate the skin We do not simulate the hands Our model is close to the Inria's iCub , but it has not been checked in detail. URDF: [ icub.urdf ] Example [ icub.cpp ] Please note that the mesh files (.glb) require assimp 5.x (and not assimp4.x usually shipped with ROS). If you cannot load the URDF, please check your assimp version. Load iCub auto robot = std :: make_shared < robot_dart :: robots :: ICub > (); // Set actuator types to VELOCITY motors so that they stay in position without any controller robot -> set_actuator_types ( \"velocity\" ); robot_dart :: RobotDARTSimu simu ( 0.001 ); simu . set_collision_detector ( \"fcl\" ); Print IMU sensor measurements std :: cout << \"Angular Position: \" << robot -> imu (). angular_position_vec (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"Angular Velocity: \" << robot -> imu (). angular_velocity (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"Linear Acceleration: \" << robot -> imu (). linear_acceleration (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"=================================\" << std :: endl ; Print Force-Torque sensor measurements std :: cout << \"FT ( force): \" << robot -> ft_foot_left (). force (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"FT (torque): \" << robot -> ft_foot_left (). torque (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"=================================\" << std :: endl ;","title":"iCub (IIT)"},{"location":"robots/#unitree-a1","text":"A1 is a quadruped robot made by the Unitree Robotics . IMU in the torso We do not simulate the foot pressure sensors (yet) One can easily add a depth camera on the head URDF: [ a1.urdf ] Example [ a1.cpp ] Load A1 auto robot = std :: make_shared < robot_dart :: robots :: A1 > (); Print IMU sensor measurements std :: cout << \"Angular Position: \" << robot -> imu (). angular_position_vec (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"Angular Velocity: \" << robot -> imu (). angular_velocity (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"Linear Acceleration: \" << robot -> imu (). linear_acceleration (). transpose (). format ( fmt ) << std :: endl ; std :: cout << \"=================================\" << std :: endl ; Add a depth camera on the head How can I attach a camera to a moving link? Please note that the mesh files (.glb) require assimp 5.x (and not assimp4.x usually shipped with ROS). If you cannot load the URDF, please check your assimp version.","title":"Unitree A1"},{"location":"robots/#dynamixel-based-hexapod-robot-inria-and-others","text":"This hexapod is a simple 6-legged robot based on dynamixel actuators. It is similar to the robot used in the paper `Robots that can adapt like animals' (Cully et al., 2015). 6 legs, 3 degrees of freedom for each leg (18 degrees of freedom) simple URDF (no meshes) URDF: [ pexod.urdf ] Example: [ hexapod.cpp ] Load Hexapod auto robot = std :: make_shared < robot_dart :: robots :: Hexapod > (); Load Pexod auto robot = std :: make_shared < robot_dart :: Robot > ( \"pexod.urdf\" );","title":"Dynamixel-based hexapod robot (Inria and others)"},{"location":"robots/#simple-arm","text":"A simple arm for educational or debugging purposes 5 degrees of freedom simple URDF (no meshes) URDF: [ arm.urdf ] Example: [ arm.cpp ] Load Simple Arm auto robot = std :: make_shared < robot_dart :: robots :: Arm > ();","title":"Simple arm"},{"location":"robots/#loading-custom-robots","text":"RobotDART gives you the ability to load custom robots that are defined in URDF , SDF , SKEL or MJCF files. For example, you can load a urdf model using: Load custom Robot auto your_robot = std :: make_shared < robot_dart :: Robot > ( \"path/to/model.urdf\" ); Load custom Robot with packages (e.g STL, DAE meshes) std :: vector < std :: pair < std :: string , std :: string >> your_model_packages = ( ' model ' , ' path / to / model / dir ' ); auto your_robot = std :: make_shared < robot_dart :: Robot > ( \"path/to/model.urdf\" , your_model_packages , \"packages\" );","title":"Loading Custom Robots"}]}